{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ranjitghadge/Credit-Card-Default-Prediction-/blob/main/Ranjit_Ghadge_Credit_Card_Default_Prediction_Capstone_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOGC-qoyhJeX"
      },
      "source": [
        "# <b><u> Project Title : Predicting whether a customer will default on his/her credit card </u></b>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y06xIdG26kRF"
      },
      "source": [
        "## <b> Problem Description </b>\n",
        "\n",
        "### This project is aimed at predicting the case of customers default payments in Taiwan. From the perspective of risk management, the result of predictive accuracy of the estimated probability of default will be more valuable than the binary result of classification - credible or not credible clients. We can use the [K-S chart](https://www.listendata.com/2019/07/KS-Statistics-Python.html) to evaluate which customers will default on their credit card payments\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlLxAtlziMbP"
      },
      "source": [
        "## <b> Data Description </b>\n",
        "\n",
        "### <b>Attribute Information: </b>\n",
        "\n",
        "### This research employed a binary variable, default payment (Yes = 1, No = 0), as the response variable. This study reviewed the literature and used the following 23 variables as explanatory variables:\n",
        "* ### X1: Amount of the given credit (NT dollar): it includes both the individual consumer credit and his/her family (supplementary) credit.\n",
        "* ### X2: Gender (1 = male; 2 = female).\n",
        "* ### X3: Education (1 = graduate school; 2 = university; 3 = high school; 4 = others).\n",
        "* ### X4: Marital status (1 = married; 2 = single; 3 = others).\n",
        "* ### X5: Age (year).\n",
        "* ### X6 - X11: History of past payment. We tracked the past monthly payment records (from April to September, 2005) as follows: X6 = the repayment status in September, 2005; X7 = the repayment status in August, 2005; . . .;X11 = the repayment status in April, 2005. The measurement scale for the repayment status is: -1 = pay duly; 1 = payment delay for one month; 2 = payment delay for two months; . . .; 8 = payment delay for eight months; 9 = payment delay for nine months and above.\n",
        "* ### X12-X17: Amount of bill statement (NT dollar). X12 = amount of bill statement in September, 2005; X13 = amount of bill statement in August, 2005; . . .; X17 = amount of bill statement in April, 2005.\n",
        "* ### X18-X23: Amount of previous payment (NT dollar). X18 = amount paid in September, 2005; X19 = amount paid in August, 2005; . . .;X23 = amount paid in April, 2005."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dByMsuzT8Tnw"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from numpy import math\n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EoyK3R5rSOi2"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "df1= drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FdFytIyGSd9E"
      },
      "outputs": [],
      "source": [
        "df=pd.read_csv('/content/drive/MyDrive/Data Science/Almabetter/Colab Notebooks/Classification Project/default of credit card clients.xls - Data.csv',header=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LOusJcdOSd6C"
      },
      "outputs": [],
      "source": [
        "#viewing dataset\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uB5gZk4WZVKL"
      },
      "source": [
        "What we know about dataset :\n",
        "\n",
        "We have records of 30000 customers. Below are the description of all features we have.\n",
        "\n",
        "* ID: ID of each client\n",
        "\n",
        "* LIMIT_BAL: Amount of given credit in NT dollars (includes individual and family/supplementary credit)\n",
        "\n",
        "* SEX: Gender (1 = male, 2 = female)\n",
        "\n",
        "* EDUCATION: (1 = graduate school, 2 = university, 3 = high school, 0,4,5,6 = others)\n",
        "\n",
        "* MARRIAGE: Marital status (0 = others, 1 = married, 2 = single, 3 = others)\n",
        "\n",
        "* AGE: Age in years\n",
        "\n",
        "**Scale for PAY_0 to PAY_6** : (-2 = No consumption, -1 = paid in full, 0 = use of revolving credit (paid minimum only), 1 = payment delay for one month, 2 = payment delay for two months, ... 8 = payment delay for eight months, 9 = payment delay for nine months and above)\n",
        "\n",
        "* PAY_0: Repayment status in September, 2005 (scale same as above)\n",
        "\n",
        "* PAY_2: Repayment status in August, 2005 (scale same as above)\n",
        "\n",
        "* PAY_3: Repayment status in July, 2005 (scale same as above)\n",
        "\n",
        "* PAY_4: Repayment status in June, 2005 (scale same as above)\n",
        "\n",
        "* PAY_5: Repayment status in May, 2005 (scale same as above)\n",
        "\n",
        "* PAY_6: Repayment status in April, 2005 (scale same as above)\n",
        "\n",
        "* BILL_AMT1: Amount of bill statement in September, 2005 (NT dollar)\n",
        "\n",
        "* BILL_AMT2: Amount of bill statement in August, 2005 (NT dollar)\n",
        "\n",
        "* BILL_AMT3: Amount of bill statement in July, 2005 (NT dollar)\n",
        "\n",
        "* BILL_AMT4: Amount of bill statement in June, 2005 (NT dollar)\n",
        "\n",
        "* BILL_AMT5: Amount of bill statement in May, 2005 (NT dollar)\n",
        "\n",
        "* BILL_AMT6: Amount of bill statement in April, 2005 (NT dollar)\n",
        "\n",
        "* PAY_AMT1: Amount of previous payment in September, 2005 (NT dollar)\n",
        "\n",
        "* PAY_AMT2: Amount of previous payment in August, 2005 (NT dollar)\n",
        "\n",
        "* PAY_AMT3: Amount of previous payment in July, 2005 (NT dollar)\n",
        "\n",
        "* PAY_AMT4: Amount of previous payment in June, 2005 (NT dollar)\n",
        "\n",
        "* PAY_AMT5: Amount of previous payment in May, 2005 (NT dollar)\n",
        "\n",
        "* PAY_AMT6: Amount of previous payment in April, 2005 (NT dollar)\n",
        "\n",
        "* default.payment.next.month: Default payment (1=yes, 0=no)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbsZiukWbCbm"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2LT1h4h4cAeM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iJuFGk6CSd1t"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q9TNbROTSdyt"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hFGkgfkCcUs2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RiPNefeJSdvu"
      },
      "outputs": [],
      "source": [
        "df.describe().T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sLceMwJMSdsl"
      },
      "outputs": [],
      "source": [
        "#check for any duplicates\n",
        "len(df[df.duplicated()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2uo1eXCxSdpd"
      },
      "outputs": [],
      "source": [
        "#columns of dataset\n",
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vniotlpldkJK"
      },
      "outputs": [],
      "source": [
        "df.isnull().sum()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9oaZft5-dkGQ"
      },
      "outputs": [],
      "source": [
        "#Plot to check null values\n",
        "plt.figure(figsize=(14,5))\n",
        "sns.heatmap(df.isnull(), cbar=True, yticklabels=False )\n",
        "plt.title(\"Missing Values Percentage\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ad0m64ofoWk"
      },
      "source": [
        "**Hence no Missing values, No null values, No Duplicates in dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijS9V8B1H4EY"
      },
      "source": [
        "**Data Processing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uw0yJhv_dkDk"
      },
      "outputs": [],
      "source": [
        "#renaming of columns\n",
        "df.rename(columns={'default payment next month' : 'IsDefaulter'}, inplace=True)\n",
        "df.rename(columns={'PAY_0':'PAY_SEPT','PAY_2':'PAY_AUG','PAY_3':'PAY_JUL','PAY_4':'PAY_JUN','PAY_5':'PAY_MAY','PAY_6':'PAY_APR'},inplace=True)\n",
        "df.rename(columns={'BILL_AMT1':'BILL_AMT_SEPT','BILL_AMT2':'BILL_AMT_AUG','BILL_AMT3':'BILL_AMT_JUL','BILL_AMT4':'BILL_AMT_JUN','BILL_AMT5':'BILL_AMT_MAY','BILL_AMT6':'BILL_AMT_APR'}, inplace = True)\n",
        "df.rename(columns={'PAY_AMT1':'PAY_AMT_SEPT','PAY_AMT2':'PAY_AMT_AUG','PAY_AMT3':'PAY_AMT_JUL','PAY_AMT4':'PAY_AMT_JUN','PAY_AMT5':'PAY_AMT_MAY','PAY_AMT6':'PAY_AMT_APR'},inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "99xAOczJJoXd"
      },
      "outputs": [],
      "source": [
        "#check for rename\n",
        "pd.set_option('display.max_columns', None)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-bB3FpHadb0"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SLVo2IXgdkAs"
      },
      "outputs": [],
      "source": [
        "#replacing values with labels\n",
        "#replacing values with there labels\n",
        "df.replace({'SEX': {1 : 'Male', 2 : 'Female'}}, inplace=True)\n",
        "df.replace({'EDUCATION' : {1 : 'Graduate School', 2 : 'University', 3 : 'High School', 4 : 'Others'}}, inplace=True)\n",
        "df.replace({'MARRIAGE' : {1 : 'Married', 2 : 'Single', 3 : 'Others'}}, inplace = True)\n",
        "df.replace({'IsDefaulter' : {1 : 'Yes', 0 : 'No'}}, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YorkEN0cdj9P"
      },
      "outputs": [],
      "source": [
        "#checking for replaced labels\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHjSs2UZbHXS"
      },
      "source": [
        "EDA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLHkKiOAdE-z"
      },
      "source": [
        "Dependent Variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l5jZo72dbr6H"
      },
      "outputs": [],
      "source": [
        "#Value counts of Isdefaulter\n",
        "df['IsDefaulter'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FWB6ykB6HkHT"
      },
      "outputs": [],
      "source": [
        "#value count plot for IsDefaulter\n",
        "plt.figure(figsize=(6,5))\n",
        "sns.countplot(x = 'IsDefaulter', data = df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3bGS9g3cHu5"
      },
      "source": [
        "Here we can see defaulters are less as compare to Non defaulter in the given dataset, So we can say that we have unbalanced dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3A5tlxudK5p"
      },
      "source": [
        "Independent variable:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2YGBYhKdVm_"
      },
      "source": [
        "Lets compare some categorical feature with target class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oRfYKckwHkDf"
      },
      "outputs": [],
      "source": [
        "#Value counts for sex category\n",
        "df['SEX'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w6-PM-Ago3Gr"
      },
      "outputs": [],
      "source": [
        "fil = (df['EDUCATION'] == 5) | (df['EDUCATION'] == 6) | (df['EDUCATION'] == 4)\n",
        "df.loc[fil, 'EDUCATION'] = 'Others'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2wXnOxDicd1l"
      },
      "outputs": [],
      "source": [
        "#Value counts for education category\n",
        "df['EDUCATION'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fcK6MHwHomEg"
      },
      "outputs": [],
      "source": [
        "#Value counts for marriage category\n",
        "fil = df['MARRIAGE']==0\n",
        "df.loc[fil,'MARRIAGE'] = 'Others'\n",
        "df['MARRIAGE'].value_counts()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFGqyKldq1kq"
      },
      "source": [
        "Now plotting a categorical features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iyUdUIGdoIaq"
      },
      "outputs": [],
      "source": [
        "categorical_features = ['SEX', 'EDUCATION', 'MARRIAGE']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZlIilQm7gNpM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BC9KDrshxKeD"
      },
      "outputs": [],
      "source": [
        "# count plot on two categorical variable\n",
        "sns.countplot(x ='MARRIAGE', hue = 'IsDefaulter', data = df)\n",
        " \n",
        "# Show the plot\n",
        "plt.show()\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GpoRTRHzgNmb"
      },
      "outputs": [],
      "source": [
        "# count plot on two categorical variable\n",
        "sns.countplot(x ='SEX', hue = 'IsDefaulter', data = df)\n",
        " \n",
        "# Show the plot\n",
        "plt.show()\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UkfUP7fLv2j7"
      },
      "outputs": [],
      "source": [
        "# count plot on two categorical variable\n",
        "sns.countplot(x ='EDUCATION', hue = 'IsDefaulter', data = df)\n",
        " \n",
        "# Show the plot\n",
        "plt.show()\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "txzlzCDqgNjL"
      },
      "outputs": [],
      "source": [
        "# count plot on two categorical variable\n",
        "plt.figure(figsize=(30,10))\n",
        "sns.countplot(x ='AGE', hue = 'IsDefaulter', data = df)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9HNqmMPHDVz"
      },
      "source": [
        "Checking Correlation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HezpJWeIHC3r"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4kQbpxmwGy7G"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20,18))\n",
        "sns.heatmap(df.corr(),annot=True,cmap=\"coolwarm\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VtesiX-1Gyt_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWQ09VcwHCZ3"
      },
      "source": [
        "Label Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eEuSIC0MHCID"
      },
      "outputs": [],
      "source": [
        "#Label encoding \n",
        "encode_num = {\"SEX\":{\"Female\":0,\"Male\":1}, \"IsDefaulter\":{\"Yes\":1,\"No\":0}}\n",
        "df=df.replace(encode_num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eGjO4kYiHCFG"
      },
      "outputs": [],
      "source": [
        "#check for changed labels\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QmaDrXaZaEUl"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5-h_o4OX3AG"
      },
      "outputs": [],
      "source": [
        "#creating dummy variables\n",
        "df = pd.get_dummies(df, columns=['EDUCATION','MARRIAGE']) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LZdp3kMHHB_F"
      },
      "outputs": [],
      "source": [
        "df.shape "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "inSNCU_0cip5"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HeQ78ow7Zuei"
      },
      "outputs": [],
      "source": [
        "df.drop(['EDUCATION_0','EDUCATION_Others','MARRIAGE_Others'], axis=1,inplace=True) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T-wQzaLcZxSC"
      },
      "outputs": [],
      "source": [
        "df.shape "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xq6EuTO6HB8Y"
      },
      "outputs": [],
      "source": [
        "#creating dummy variables by droping first variable\n",
        "df = pd.get_dummies(df, columns=['PAY_SEPT', 'PAY_AUG', 'PAY_JUL', 'PAY_JUN', 'PAY_MAY', 'PAY_APR'], drop_first = True )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "96O3OgpLHB5w"
      },
      "outputs": [],
      "source": [
        "df.shape "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VCltj1pXHB3f"
      },
      "outputs": [],
      "source": [
        "#checking all variables\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I64ROmrIj9zS"
      },
      "source": [
        "Handling Class Imbalance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_-dAM4Hj0mj"
      },
      "source": [
        "### **SMOTE** ***- Synthetic Minority Oversampling Technique***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DzvMKVZnHB2P"
      },
      "outputs": [],
      "source": [
        "#importing SMOTE to handle class imbalance\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "smote = SMOTE()\n",
        "\n",
        "# fit predictor and target variable\n",
        "x_smote, y_smote = smote.fit_resample(df[(i for i in list(df.describe(include='all').columns) if i != 'IsDefaulter')], df['IsDefaulter'])\n",
        "\n",
        "print('Original unbalanced dataset shape', len(df))\n",
        "print('Resampled balanced dataset shape', len(y_smote))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vmXziCqfHBx3"
      },
      "outputs": [],
      "source": [
        "#creating new dataframe from balanced dataset after SMOTE\n",
        "balanced_df = pd.DataFrame(x_smote, columns=list(i for i in list(df.describe(include='all').columns) if i != 'IsDefaulter'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fc2q3bAggNYZ"
      },
      "outputs": [],
      "source": [
        "#adding target variable to new created dataframe\n",
        "balanced_df['IsDefaulter'] = y_smote"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8aLkaEJFgNGE"
      },
      "outputs": [],
      "source": [
        "#checking for class imbalance\n",
        "plt.figure(figsize=(5,5))\n",
        "sns.countplot('IsDefaulter', data = balanced_df, palette = \"Set1\" )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LQyp_c67HkAM"
      },
      "outputs": [],
      "source": [
        "#shape of balanced dataframe\n",
        "balanced_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u2Z8pU1mHj8f"
      },
      "outputs": [],
      "source": [
        "#removing feature ID from dataset\n",
        "balanced_df.drop('ID',axis = 1, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Wdfzm3HHj5N"
      },
      "outputs": [],
      "source": [
        "#final dataset\n",
        "balanced_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wi-NVFcPHj25"
      },
      "outputs": [],
      "source": [
        "#seperating dependant and independant variabales\n",
        "X = balanced_df[(list(i for i in list(balanced_df.describe(include='all').columns) if i != 'IsDefaulter'))]\n",
        "y = balanced_df['IsDefaulter']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zJL98l5sHjxR"
      },
      "outputs": [],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x_-SPZR7HjtS"
      },
      "outputs": [],
      "source": [
        "y.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIgCZzACRcu0"
      },
      "source": [
        "Data Transformation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kVd2a4dRRfZq"
      },
      "outputs": [],
      "source": [
        "#importing libraries for data transformation\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KpfgKTCRooE"
      },
      "source": [
        "Train Test Splitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O6bRbVZlRrHW"
      },
      "outputs": [],
      "source": [
        "#importing libraries for splitting data into training and testing dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=42, stratify=y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nuWqNQ1PRzsz"
      },
      "outputs": [],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xs2Pq9uER3L8"
      },
      "outputs": [],
      "source": [
        "X_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6IJlknDHVJF"
      },
      "source": [
        "Model Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tm47hBpLP6ls"
      },
      "source": [
        "Logistic regression model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qZpgkmuMHjp6"
      },
      "outputs": [],
      "source": [
        "#importing logistic regression and evaluation metrics\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score, confusion_matrix, roc_curve, auc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hDGKOoDPHjmW"
      },
      "outputs": [],
      "source": [
        "#fitting data into Logistic Regression\n",
        "logi = LogisticRegression(fit_intercept=True, max_iter=10000)\n",
        "logi.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oVrSDzNYHjiz"
      },
      "outputs": [],
      "source": [
        "#class prediction of y\n",
        "y_pred_logi = logi.predict(X_test)\n",
        "y_train_pred_logi=logi.predict(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WQZPtKneHjfe"
      },
      "outputs": [],
      "source": [
        "#getting all score for logistic regression\n",
        "train_accuracy_logi = round(accuracy_score(y_train_pred_logi,y_train), 3)\n",
        "accuracy_logi = round(accuracy_score(y_pred_logi,y_test), 3)\n",
        "precision_score_logi = round(precision_score(y_pred_logi,y_test), 3)\n",
        "recall_score_logi = round(recall_score(y_pred_logi,y_test), 3)\n",
        "f1_score_logi = round(f1_score(y_pred_logi,y_test), 3)\n",
        "roc_score_logi = round(roc_auc_score(y_pred_logi,y_test), 3)\n",
        "\n",
        "print(\"The accuracy on train data is \", train_accuracy_logi)\n",
        "print(\"The accuracy on test data is \", accuracy_logi)\n",
        "print(\"The precision on test data is \", precision_score_logi)\n",
        "print(\"The recall on test data is \", recall_score_logi)\n",
        "print(\"The f1 on test data is \", f1_score_logi)\n",
        "print(\"The roc_score on test data is \", roc_score_logi)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TdE5S1bmHjcL"
      },
      "outputs": [],
      "source": [
        "#Confusion matrix\n",
        "labels = ['Not Defaulter', 'Defaulter']\n",
        "cm_logi = confusion_matrix(y_test, y_pred_logi )\n",
        "print(cm_logi)\n",
        "\n",
        "#plot confusion matrix\n",
        "ax= plt.subplot()\n",
        "sns.heatmap(cm_logi, annot=True, ax = ax)\n",
        "\n",
        "# labels, title and ticks\n",
        "ax.set_xlabel('Predicted labels')\n",
        "ax.set_ylabel('True labels')\n",
        "ax.set_title('Confusion Matrix - Logistic Regression')\n",
        "ax.xaxis.set_ticklabels(labels)\n",
        "ax.yaxis.set_ticklabels(labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09NocwvfTCeq"
      },
      "source": [
        "Decision tree classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "johaG-LQHjYz"
      },
      "outputs": [],
      "source": [
        "#importing Decision Tree Classifier\n",
        "from sklearn.tree import DecisionTreeClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GmW2i4KGHjVY"
      },
      "outputs": [],
      "source": [
        "#fitting data into Decision Tree Classifier\n",
        "dtc = DecisionTreeClassifier()\n",
        "dtc.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xJmxejolHjSB"
      },
      "outputs": [],
      "source": [
        "#class prediction of y\n",
        "y_pred_dtc = dtc.predict(X_test)\n",
        "y_train_pred_dtc=dtc.predict(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Itjb1sqiHjO1"
      },
      "outputs": [],
      "source": [
        "#getting all scores for Decision Tree Classifier\n",
        "train_accuracy_dtc = round(accuracy_score(y_train_pred_dtc,y_train), 3)\n",
        "accuracy_dtc = round(accuracy_score(y_pred_dtc,y_test), 3)\n",
        "precision_score_dtc = round(precision_score(y_pred_dtc,y_test), 3)\n",
        "recall_score_dtc = round(recall_score(y_pred_dtc,y_test), 3)\n",
        "f1_score_dtc = round(f1_score(y_pred_dtc,y_test), 3)\n",
        "roc_score_dtc = round(roc_auc_score(y_pred_dtc,y_test), 3)\n",
        "\n",
        "print(\"The accuracy on train data is \", train_accuracy_dtc)\n",
        "print(\"The accuracy on test data is \", accuracy_dtc)\n",
        "print(\"The precision on test data is \", precision_score_dtc)\n",
        "print(\"The recall on test data is \", recall_score_dtc)\n",
        "print(\"The f1 on test data is \", f1_score_dtc)\n",
        "print(\"The roc_score on test data is \", roc_score_dtc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wl-54Z7oHjLq"
      },
      "outputs": [],
      "source": [
        "# Get the confusion matrix for desicion tree\n",
        "labels = ['Not Defaulter', 'Defaulter']\n",
        "cm_dt = confusion_matrix(y_test, y_pred_dtc )\n",
        "print(cm_dt)\n",
        "\n",
        "#plot confusion matrix\n",
        "ax= plt.subplot()\n",
        "sns.heatmap(cm_dt, annot=True, ax = ax)\n",
        "\n",
        "# labels, title and ticks\n",
        "ax.set_xlabel('Predicted labels')\n",
        "ax.set_ylabel('True labels')\n",
        "ax.set_title('Confusion Matrix - Decision Tree')\n",
        "ax.xaxis.set_ticklabels(labels)\n",
        "ax.yaxis.set_ticklabels(labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iiybEynlT6Le"
      },
      "source": [
        "Random Forest Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hIEwl7dFHjIY"
      },
      "outputs": [],
      "source": [
        "#importing Random Forest Classifier\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZt_PHShHjE5"
      },
      "outputs": [],
      "source": [
        "#fitting data into Random Forest Classifier\n",
        "rfc=RandomForestClassifier(n_estimators=50)\n",
        "rfc.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZjUHDUGOHjBj"
      },
      "outputs": [],
      "source": [
        "#class prediction of y\n",
        "y_pred_rfc=rfc.predict(X_test)\n",
        "y_train_pred_rfc=rfc.predict(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hsj6rVvUHi-B"
      },
      "outputs": [],
      "source": [
        "#getting all scores for Random Forest Classifier\n",
        "train_accuracy_rfc = round(accuracy_score(y_train_pred_rfc,y_train), 3)\n",
        "accuracy_rfc = round(accuracy_score(y_pred_rfc,y_test), 3)\n",
        "precision_score_rfc = round(precision_score(y_pred_rfc,y_test), 3)\n",
        "recall_score_rfc = round(recall_score(y_pred_rfc,y_test), 3)\n",
        "f1_score_rfc = round(f1_score(y_pred_rfc,y_test), 3)\n",
        "roc_score_rfc = round(roc_auc_score(y_pred_rfc,y_test), 3)\n",
        "\n",
        "print(\"The accuracy on train data is \", train_accuracy_rfc)\n",
        "print(\"The accuracy on test data is \", accuracy_rfc)\n",
        "print(\"The precision on test data is \", precision_score_rfc)\n",
        "print(\"The recall on test data is \", recall_score_rfc)\n",
        "print(\"The f1 on test data is \", f1_score_rfc)\n",
        "print(\"The roc_score on test data is \", roc_score_rfc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zBpluEdWHi6k"
      },
      "outputs": [],
      "source": [
        "# Get the confusion matrix for Random Forest Classifier\n",
        "labels = ['Not Defaulter', 'Defaulter']\n",
        "cm_rfc = confusion_matrix(y_test, y_pred_rfc )\n",
        "print(cm_rfc)\n",
        "\n",
        "#plot confusion matrix\n",
        "ax= plt.subplot()\n",
        "sns.heatmap(cm_rfc, annot=True, ax = ax)\n",
        "\n",
        "# labels, title and ticks\n",
        "ax.set_xlabel('Predicted labels')\n",
        "ax.set_ylabel('True labels')\n",
        "ax.set_title('Confusion Matrix - Random Forest Classifier')\n",
        "ax.xaxis.set_ticklabels(labels)\n",
        "ax.yaxis.set_ticklabels(labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlhCIQE_WQWi"
      },
      "source": [
        "Support Vector Machine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VprCpY9XWoJ0"
      },
      "outputs": [],
      "source": [
        "#importing Support vector Classifier\n",
        "from sklearn.svm import SVC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eu-tDRzcWoJ1"
      },
      "outputs": [],
      "source": [
        "#fitting data into Support Vector Classifier\n",
        "svm=SVC(probability=True)\n",
        "svm.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8eAiekQGWoJ2"
      },
      "outputs": [],
      "source": [
        "#class prediction of y\n",
        "y_pred_svm=svm.predict(X_test)\n",
        "y_train_pred_svm=svm.predict(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9Xm-1CUWoJ3"
      },
      "outputs": [],
      "source": [
        "#getting all scores for Support Vector Classifier\n",
        "train_accuracy_svm = round(accuracy_score(y_train_pred_svm,y_train), 3)\n",
        "accuracy_svm = round(accuracy_score(y_pred_svm,y_test), 3)\n",
        "precision_score_svm = round(precision_score(y_pred_svm,y_test), 3)\n",
        "recall_score_svm = round(recall_score(y_pred_svm,y_test), 3)\n",
        "f1_score_svm = round(f1_score(y_pred_svm,y_test), 3)\n",
        "roc_score_svm = round(roc_auc_score(y_pred_svm,y_test), 3)\n",
        "\n",
        "print(\"The accuracy on train data is \", train_accuracy_svm)\n",
        "print(\"The accuracy on test data is \", accuracy_svm)\n",
        "print(\"The precision on test data is \", precision_score_svm)\n",
        "print(\"The recall on test data is \", recall_score_svm)\n",
        "print(\"The f1 on test data is \", f1_score_svm)\n",
        "print(\"The roc_score on test data is \", roc_score_svm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BMLQBP3sWoJ4"
      },
      "outputs": [],
      "source": [
        "# Get the confusion matrix for Support Vector Classifier\n",
        "labels = ['Not Defaulter', 'Defaulter']\n",
        "cm_svm = confusion_matrix(y_test, y_pred_svm )\n",
        "print(cm_svm)\n",
        "\n",
        "#plot confusion matrix\n",
        "ax= plt.subplot()\n",
        "sns.heatmap(cm_svm, annot=True, ax = ax)\n",
        "\n",
        "# labels, title and ticks\n",
        "ax.set_xlabel('Predicted labels')\n",
        "ax.set_ylabel('True labels')\n",
        "ax.set_title('Confusion Matrix - SVM')\n",
        "ax.xaxis.set_ticklabels(labels)\n",
        "ax.yaxis.set_ticklabels(labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdclvwJCYWPG"
      },
      "source": [
        "Gradient Boosting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yoXsPW6oHi0R"
      },
      "outputs": [],
      "source": [
        "#importing Gradient Boosting Classifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80NokemsHiwl"
      },
      "outputs": [],
      "source": [
        "#fitting data into Gradient Boosting Classifier\n",
        "gbc = GradientBoostingClassifier(random_state=42)\n",
        "gbc.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uf8qOCHWHitQ"
      },
      "outputs": [],
      "source": [
        "#class prediction of y\n",
        "y_pred_gbc=gbc.predict(X_test)\n",
        "y_train_pred_gbc=gbc.predict(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DYFXiK-6Hip8"
      },
      "outputs": [],
      "source": [
        "#getting all scores for Gradient Boosting Classifier\n",
        "train_accuracy_gbc = round(accuracy_score(y_train_pred_gbc,y_train), 3)\n",
        "accuracy_gbc = round(accuracy_score(y_pred_gbc,y_test), 3)\n",
        "precision_score_gbc = round(precision_score(y_pred_gbc,y_test), 3)\n",
        "recall_score_gbc = round(recall_score(y_pred_gbc,y_test), 3)\n",
        "f1_score_gbc = round(f1_score(y_pred_gbc,y_test), 3)\n",
        "roc_score_gbc = round(roc_auc_score(y_pred_gbc,y_test), 3)\n",
        "\n",
        "print(\"The accuracy on train data is \", train_accuracy_gbc)\n",
        "print(\"The accuracy on test data is \", accuracy_gbc)\n",
        "print(\"The precision on test data is \", precision_score_gbc)\n",
        "print(\"The recall on test data is \", recall_score_gbc)\n",
        "print(\"The f1 on test data is \", f1_score_gbc)\n",
        "print(\"The roc_score on test data is \", roc_score_gbc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AgqYxXEOHims"
      },
      "outputs": [],
      "source": [
        "# Get the confusion matrix for Gradient Boosting Classifier\n",
        "labels = ['Not Defaulter', 'Defaulter']\n",
        "cm_gbc = confusion_matrix(y_test, y_pred_gbc )\n",
        "print(cm_gbc)\n",
        "\n",
        "#plot confusion matrix\n",
        "ax= plt.subplot()\n",
        "sns.heatmap(cm_gbc, annot=True, ax = ax)\n",
        "\n",
        "# labels, title and ticks\n",
        "ax.set_xlabel('Predicted labels')\n",
        "ax.set_ylabel('True labels')\n",
        "ax.set_title('Confusion Matrix - Gradient Boosting Classifier')\n",
        "ax.xaxis.set_ticklabels(labels)\n",
        "ax.yaxis.set_ticklabels(labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTBKNbciYl0z"
      },
      "source": [
        "XG Boosting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6dDDEZyqHijg"
      },
      "outputs": [],
      "source": [
        "#importing XG Boosting Classifier\n",
        "from xgboost import XGBClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_vaShen0HigT"
      },
      "outputs": [],
      "source": [
        "#fitting data into XG Boosting Classifier\n",
        "xgb = XGBClassifier()\n",
        "xgb.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eYYSkNC-HidC"
      },
      "outputs": [],
      "source": [
        "#class prediction of y\n",
        "y_pred_xgb=xgb.predict(X_test)\n",
        "y_train_pred_xgb=xgb.predict(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eftfwi2THiaF"
      },
      "outputs": [],
      "source": [
        "#getting all scores for XG Boosting Classifier\n",
        "train_accuracy_xgb = round(accuracy_score(y_train_pred_xgb,y_train), 3)\n",
        "accuracy_xgb = round(accuracy_score(y_pred_xgb,y_test), 3)\n",
        "precision_score_xgb = round(precision_score(y_pred_xgb,y_test), 3)\n",
        "recall_score_xgb = round(recall_score(y_pred_xgb,y_test), 3)\n",
        "f1_score_xgb = round(f1_score(y_pred_xgb,y_test), 3)\n",
        "roc_score_xgb = round(roc_auc_score(y_pred_xgb,y_test), 3)\n",
        "\n",
        "print(\"The accuracy on train data is \", train_accuracy_xgb)\n",
        "print(\"The accuracy on test data is \", accuracy_xgb)\n",
        "print(\"The precision on test data is \", precision_score_xgb)\n",
        "print(\"The recall on test data is \", recall_score_xgb)\n",
        "print(\"The f1 on test data is \", f1_score_xgb)\n",
        "print(\"The roc_score on test data is \", roc_score_xgb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "buTimikBHiWc"
      },
      "outputs": [],
      "source": [
        "# Get the confusion matrix for XG Boosting Classifier\n",
        "labels = ['Not Defaulter', 'Defaulter']\n",
        "cm_xgb = confusion_matrix(y_test, y_pred_xgb )\n",
        "print(cm_xgb)\n",
        "\n",
        "#plot confusion matrix\n",
        "ax= plt.subplot()\n",
        "sns.heatmap(cm_xgb, annot=True, ax = ax)\n",
        "\n",
        "# labels, title and ticks\n",
        "ax.set_xlabel('Predicted labels')\n",
        "ax.set_ylabel('True labels')\n",
        "ax.set_title('Confusion Matrix - XG Boosting Classifier')\n",
        "ax.xaxis.set_ticklabels(labels)\n",
        "ax.yaxis.set_ticklabels(labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmLI08fbZW23"
      },
      "source": [
        "Model Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U1gxjJEnHiTN"
      },
      "outputs": [],
      "source": [
        "all_lassifiers = ['Logistic Regression', 'Decision Tree', 'Random Forest', 'SVM', 'Gradient Boosting', 'XG Boosting']\n",
        "all_train_accuracy = [train_accuracy_logi, train_accuracy_dtc, train_accuracy_rfc, train_accuracy_svm, train_accuracy_gbc, train_accuracy_xgb]\n",
        "all_test_accuracy = [accuracy_logi, accuracy_dtc, accuracy_rfc, accuracy_svm, accuracy_gbc, accuracy_xgb]\n",
        "all_precision_score = [precision_score_logi, precision_score_dtc, precision_score_rfc, precision_score_svm, precision_score_gbc, precision_score_xgb]\n",
        "all_recall_score = [recall_score_logi, recall_score_dtc, recall_score_rfc, recall_score_svm, recall_score_gbc, recall_score_xgb]\n",
        "all_f1_score = [f1_score_logi, f1_score_dtc, f1_score_rfc, f1_score_svm, f1_score_gbc, f1_score_xgb]\n",
        "all_auc_score = [roc_score_logi, roc_score_dtc, roc_score_rfc, roc_score_svm, roc_score_gbc, roc_score_xgb]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQf698DnZdQv"
      },
      "outputs": [],
      "source": [
        "compare_df = pd.DataFrame({'Classifier':all_lassifiers, 'Train Accuracy': all_train_accuracy, 'Test Accuracy': all_test_accuracy, 'Precision': all_precision_score, 'Recall': all_recall_score, 'F1 Score': all_f1_score , 'AUC': all_auc_score})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5bKqRPaOZeGL"
      },
      "outputs": [],
      "source": [
        "compare_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "undNoGzLZhOw"
      },
      "outputs": [],
      "source": [
        "compare_df.sort_values(by=['Test Accuracy'], ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tW11_L1fiYf"
      },
      "source": [
        "Combined ROC Curve For All Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YjhiKdx0fsYY"
      },
      "outputs": [],
      "source": [
        "#importing roc curve\n",
        "from sklearn.metrics import roc_curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fHIhAMVYfsV3"
      },
      "outputs": [],
      "source": [
        "#probabilty prediction of y for all model\n",
        "y_pred_proba_logi = logi.predict_proba(X_test)[:,1]\n",
        "y_pred_proba_dtc = dtc.predict_proba(X_test)[:,1]\n",
        "y_pred_proba_rfc = rfc.predict_proba(X_test)[:,1]\n",
        "y_pred_proba_svm = svm.predict_proba(X_test)[:,1]\n",
        "y_pred_proba_gbc = gbc.predict_proba(X_test)[:,1]\n",
        "y_pred_proba_xgb = xgb.predict_proba(X_test)[:,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xohkfgrBfsRp"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(10,8)) \n",
        "\n",
        "fpr_logi, tpr_logi, _logi = roc_curve(y_test,  y_pred_proba_logi)\n",
        "fpr_dtc, tpr_dtc, _dtc = roc_curve(y_test,  y_pred_proba_dtc)\n",
        "fpr_rfc, tpr_rfc, _rfc = roc_curve(y_test,  y_pred_proba_rfc)\n",
        "fpr_svm, tpr_svm, _svm = roc_curve(y_test,  y_pred_proba_svm)\n",
        "fpr_gbc, tpr_gbc, _gbc = roc_curve(y_test,  y_pred_proba_gbc)\n",
        "fpr_xgb, tpr_xgb, _xgb = roc_curve(y_test,  y_pred_proba_xgb)\n",
        "\n",
        "plt.plot(fpr_logi, tpr_logi)\n",
        "plt.plot(fpr_dtc, tpr_dtc)\n",
        "plt.plot(fpr_rfc, tpr_rfc)\n",
        "plt.plot(fpr_svm, tpr_svm)\n",
        "plt.plot(fpr_gbc, tpr_gbc)\n",
        "plt.plot(fpr_xgb, tpr_xgb)\n",
        "\n",
        "plt.plot([0,1], [0,1], color='black', linestyle='--')\n",
        "\n",
        "plt.xlabel(\"Flase Positive Rate\", fontsize=12)\n",
        "plt.ylabel(\"True Positive Rate\", fontsize=12)\n",
        "plt.title('Combined ROC Curve', fontsize=15)\n",
        "\n",
        "plt.legend([\"Logistic\", \"Decision Tree\", \"Random Forest\", \"SVM\", \"GB Boost\" \"XG Boost\"], prop={'size':13}, loc='lower right' )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B11OEmQZf6h3"
      },
      "source": [
        "Cross Validation & Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zGNTUw46fsP3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CgdNOkfNX2wC"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93y49U1mNisy"
      },
      "source": [
        "## **Logistic Regression Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zP2dZF0ONqAs"
      },
      "outputs": [],
      "source": [
        "# penalty in Logistic Regression Classifier\n",
        "penalties = ['l1','l2', 'elasticnet', 'none']\n",
        "\n",
        "# hyperparameter C\n",
        "C= [0.0001, 0.001, 0.1, 0.5, 0.75, 1, 1.25, 1.5, 5, 10]\n",
        "\n",
        "# Hyperparameter Grid\n",
        "param_dict = {'penalty':penalties,\n",
        "              'max_iter' : [100, 1000,2500, 5000],\n",
        "              'C' : C }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6doUX0kVNrSy"
      },
      "outputs": [],
      "source": [
        "# Create an instance of the Logistic Regression\n",
        "logi = LogisticRegression()\n",
        "\n",
        "# Grid search\n",
        "logi_grid = GridSearchCV(estimator=logi,\n",
        "                       param_grid = param_dict,\n",
        "                       cv = 5, verbose=3, n_jobs = -1, scoring='roc_auc')\n",
        "# fitting model\n",
        "logi_grid.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Gc0cG4phRLlj"
      },
      "outputs": [],
      "source": [
        "logi_grid.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "mTrUOdImRLlq"
      },
      "outputs": [],
      "source": [
        "logi_grid.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "rwTQrv9qRLlq"
      },
      "outputs": [],
      "source": [
        "logi_optimal_model = logi_grid.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "gw1z__KlRLlr"
      },
      "outputs": [],
      "source": [
        "#class prediction of y on train and test\n",
        "y_pred_logi_grid = logi_optimal_model.predict(X_test)\n",
        "y_train_pred_logi_grid = logi_optimal_model.predict(X_train)\n",
        "\n",
        "# Get the probabilities on train and test\n",
        "y_pred_prob_logi_grid = logi_optimal_model.predict_proba(X_train)[:,1]\n",
        "y_train_pred_prob_logi_grid = logi_optimal_model.predict_proba(X_test)[:,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Zk_nJEJkRLlr"
      },
      "outputs": [],
      "source": [
        "#getting all scores for Logistic Regression after CV and Hyperparameter Tunning\n",
        "train_accuracy_logi_grid = round(accuracy_score(y_train_pred_logi_grid,y_train), 3)\n",
        "accuracy_logi_grid = round(accuracy_score(y_pred_logi_grid,y_test), 3)\n",
        "precision_score_logi_grid = round(precision_score(y_pred_logi_grid, y_test), 3)\n",
        "recall_score_logi_grid = round(recall_score(y_pred_logi_grid,y_test), 3)\n",
        "f1_score_logi_grid = round(f1_score(y_pred_logi_grid,y_test), 3)\n",
        "auc_logi_grid = round(roc_auc_score(y_pred_logi_grid,y_test), 3)\n",
        "\n",
        "print(\"The accuracy on train data is \", train_accuracy_logi_grid)\n",
        "print(\"The accuracy on test data is \", accuracy_logi_grid)\n",
        "print(\"The precision on test data is \", precision_score_logi_grid)\n",
        "print(\"The recall on test data is \", recall_score_logi_grid)\n",
        "print(\"The f1 on test data is \", f1_score_logi_grid)\n",
        "print(\"The auc on test data is \", auc_logi_grid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "aK8SpyreNrMc"
      },
      "outputs": [],
      "source": [
        "# Get the confusion matrices for train and test\n",
        "train_cm_logi_grid = confusion_matrix(y_train,y_train_pred_logi_grid)\n",
        "test_cm_logi_grid = confusion_matrix(y_test,y_pred_logi_grid )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "dSkMmBj9oH83"
      },
      "outputs": [],
      "source": [
        "train_cm_logi_grid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ycJ9Q_bqoKuk"
      },
      "outputs": [],
      "source": [
        "test_cm_logi_grid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "usq4TOmoT534"
      },
      "outputs": [],
      "source": [
        "# The maximum depth of the tree\n",
        "depth_of_tree = [20,25,30,35]\n",
        "\n",
        "# The minimum number of samples required to split an internal node\n",
        "min_samples_split = [0.001,0.01,0.05]\n",
        "\n",
        "# Minimum number of samples required at each leaf node\n",
        "min_samples_leaf = [40,50,60]\n",
        "\n",
        "# Hyperparameter Grid\n",
        "param_dict = {'max_depth': depth_of_tree,\n",
        "              'min_samples_split':min_samples_split,\n",
        "              'min_samples_leaf': min_samples_leaf}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Di1axB0nT538"
      },
      "outputs": [],
      "source": [
        "# Create an instance of the decision tree\n",
        "dtc = DecisionTreeClassifier()\n",
        "\n",
        "# Grid search\n",
        "dtc_grid = GridSearchCV(estimator=dtc,\n",
        "                       param_grid = param_dict,\n",
        "                       cv = 5, verbose=3, n_jobs = -1, scoring='roc_auc')\n",
        "# fitting model\n",
        "dtc_grid.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "E7_AeaxtT539"
      },
      "outputs": [],
      "source": [
        "dtc_grid.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "u1alKarGT539"
      },
      "outputs": [],
      "source": [
        "dtc_grid.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZcjDMtTMT539"
      },
      "outputs": [],
      "source": [
        "dtc_optimal_model = dtc_grid.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hkREOs4-T539"
      },
      "outputs": [],
      "source": [
        "#class prediction of y on train and test\n",
        "y_pred_dtc_grid=dtc_optimal_model.predict(X_test)\n",
        "y_train_pred_dtc_grid=dtc_optimal_model.predict(X_train)\n",
        "\n",
        "# Get the probabilities on train and test\n",
        "y_pred_prob_dtc_grid = dtc_optimal_model.predict_proba(X_train)[:,1]\n",
        "y_train_pred_prob_dtc_grid = dtc_optimal_model.predict_proba(X_test)[:,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Cr2rxcIFT539"
      },
      "outputs": [],
      "source": [
        "#getting all scores for decision tree after CV and Hyperparameter Tunning\n",
        "train_accuracy_dtc_grid = round(accuracy_score(y_train_pred_dtc_grid,y_train), 3)\n",
        "accuracy_dtc_grid = round(accuracy_score(y_pred_dtc_grid,y_test), 3)\n",
        "precision_score_dtc_grid = round(precision_score(y_pred_dtc_grid,y_test), 3)\n",
        "recall_score_dtc_grid = round(recall_score(y_pred_dtc_grid,y_test), 3)\n",
        "f1_score_dtc_grid = round(f1_score(y_pred_dtc_grid,y_test), 3)\n",
        "auc_dtc_grid = round(roc_auc_score(y_pred_dtc_grid,y_test), 3)\n",
        "\n",
        "print(\"The accuracy on train data is \", train_accuracy_dtc_grid)\n",
        "print(\"The accuracy on test data is \", accuracy_dtc_grid)\n",
        "print(\"The precision on test data is \", precision_score_dtc_grid)\n",
        "print(\"The recall on test data is \", recall_score_dtc_grid)\n",
        "print(\"The f1 on test data is \", f1_score_dtc_grid)\n",
        "print(\"The auc on test data is \", auc_dtc_grid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hlOmd91jT53-"
      },
      "outputs": [],
      "source": [
        "# Get the confusion matrices for train and test\n",
        "train_cm_dtc_grid = confusion_matrix(y_train,y_train_pred_dtc_grid)\n",
        "test_cm_dtc_grid = confusion_matrix(y_test,y_pred_dtc_grid )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "C_X0gBgoofNj"
      },
      "outputs": [],
      "source": [
        "train_cm_dtc_grid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vbCgSb8nofKy"
      },
      "outputs": [],
      "source": [
        "test_cm_dtc_grid"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nI6dccfZB2p"
      },
      "source": [
        "## **Support Vector Machine**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6xpR1UZm-TWc"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "NdYV19QiZT5h"
      },
      "outputs": [],
      "source": [
        "# Hyperparameter Grid\n",
        "param_dict = {'C':[1, 10] ,\n",
        "              'kernel': ['rbf']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLGZl6aTZT5m",
        "outputId": "0caff4d4-62ee-415e-c6df-b2e59ca47939"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=2, estimator=SVC(probability=True), n_jobs=-1,\n",
              "                   param_distributions={'C': [1, 10], 'kernel': ['rbf']},\n",
              "                   scoring='roc_auc', verbose=2)"
            ]
          },
          "execution_count": 324,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create an instance of the support vector classifier\n",
        "svm=SVC(probability=True)\n",
        "\n",
        "# Grid search\n",
        "svm_grid = RandomizedSearchCV(estimator = svm, param_distributions = param_dict,\n",
        "                       cv = 2, verbose=2, n_jobs = -1, scoring= 'roc_auc')\n",
        "# fitting model\n",
        "svm_grid.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fXzE1jqZT5n",
        "outputId": "34995c65-bde3-4abc-a89e-84fa6fada56f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SVC(C=1, probability=True)"
            ]
          },
          "execution_count": 325,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "svm_grid.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "xN3lCCyYZT5n",
        "outputId": "eb41d02a-16f2-428b-fc7f-294caff3b623"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'kernel': 'rbf', 'C': 1}"
            ]
          },
          "execution_count": 326,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "svm_grid.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Bs0xWqoLZT5n"
      },
      "outputs": [],
      "source": [
        "svm_optimal_model = svm_grid.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7BAu0wsWZT5n"
      },
      "outputs": [],
      "source": [
        "#class prediction of y on train and test\n",
        "y_pred_svm_grid=svm_optimal_model.predict(X_test)\n",
        "y_train_pred_svm_grid=svm_optimal_model.predict(X_train)\n",
        "\n",
        "# Get the probabilities on train and test\n",
        "y_pred_prob_svm_grid = svm_optimal_model.predict_proba(X_train)[:,1]\n",
        "y_train_pred_prob_svm_grid = svm_optimal_model.predict_proba(X_test)[:,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "UKTY5DGoZT5o",
        "outputId": "d1d684cb-2642-4657-8ee2-e9de8906434e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The accuracy on train data is  0.847\n",
            "The accuracy on test data is  0.841\n",
            "The precision on test data is  0.767\n",
            "The recall on test data is  0.9\n",
            "The f1 on test data is  0.828\n",
            "The auc on test data is  0.849\n"
          ]
        }
      ],
      "source": [
        "#getting all scores for Support Vector Classifier after CV and Hyperparameter Tunning\n",
        "train_accuracy_svm_grid = round(accuracy_score(y_train_pred_svm_grid,y_train), 3)\n",
        "accuracy_svm_grid = round(accuracy_score(y_pred_svm_grid,y_test), 3)\n",
        "precision_score_svm_grid = round(precision_score(y_pred_svm_grid,y_test), 3)\n",
        "recall_score_svm_grid = round(recall_score(y_pred_svm_grid,y_test), 3)\n",
        "f1_score_svm_grid = round(f1_score(y_pred_svm_grid,y_test), 3)\n",
        "auc_svm_grid = round(roc_auc_score(y_pred_svm_grid,y_test), 3)\n",
        "\n",
        "print(\"The accuracy on train data is \", train_accuracy_svm_grid)\n",
        "print(\"The accuracy on test data is \", accuracy_svm_grid)\n",
        "print(\"The precision on test data is \", precision_score_svm_grid)\n",
        "print(\"The recall on test data is \", recall_score_svm_grid)\n",
        "print(\"The f1 on test data is \", f1_score_svm_grid)\n",
        "print(\"The auc on test data is \", auc_svm_grid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WXjPUQAdZT5o"
      },
      "outputs": [],
      "source": [
        "# Get the confusion matrices for train and test\n",
        "train_cm_svm_grid = confusion_matrix(y_train,y_train_pred_svm_grid)\n",
        "test_cm_svm_grid = confusion_matrix(y_test,y_pred_svm_grid )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "mHDxrX5fTm0n",
        "outputId": "d8809cd8-f74e-4c01-fbec-b3888ba6af89"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[17347,  1344],\n",
              "       [ 4377, 14314]])"
            ]
          },
          "execution_count": 331,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_cm_svm_grid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q76hFgK-heP2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGJ-gRiYVMCx"
      },
      "source": [
        "## **Random Forest Classifer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "R-vfSURrIqpl"
      },
      "outputs": [],
      "source": [
        "# Number of trees\n",
        "n_estimators = [100,150,200]\n",
        "\n",
        "# Maximum depth of trees\n",
        "max_depth = [10,20,30]\n",
        "\n",
        "# Minimum number of samples required to split a node\n",
        "min_samples_split = [50,100,150]\n",
        "\n",
        "# Minimum number of samples required at each leaf node\n",
        "min_samples_leaf = [40,50]\n",
        "\n",
        "# Hyperparameter Grid\n",
        "param_dict = {'n_estimators' : n_estimators,\n",
        "              'max_depth' : max_depth,\n",
        "              'min_samples_split' : min_samples_split,\n",
        "              'min_samples_leaf' : min_samples_leaf}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Bg4U0X3Iz9O",
        "outputId": "a6fbdaf0-11de-41a7-cfa0-8dc8f0a0ab4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
            "[CV] END max_depth=10, min_samples_leaf=40, min_samples_split=50, n_estimators=100; total time=   4.1s\n",
            "[CV] END max_depth=10, min_samples_leaf=40, min_samples_split=50, n_estimators=100; total time=   4.3s\n",
            "[CV] END max_depth=10, min_samples_leaf=40, min_samples_split=50, n_estimators=100; total time=   4.2s\n",
            "[CV] END max_depth=10, min_samples_leaf=40, min_samples_split=50, n_estimators=100; total time=   4.1s\n",
            "[CV] END max_depth=10, min_samples_leaf=40, min_samples_split=50, n_estimators=100; total time=   4.3s\n",
            "[CV] END max_depth=10, min_samples_leaf=40, min_samples_split=50, n_estimators=150; total time=   6.3s\n",
            "[CV] END max_depth=10, min_samples_leaf=40, min_samples_split=50, n_estimators=150; total time=   6.2s\n",
            "[CV] END max_depth=10, min_samples_leaf=40, min_samples_split=50, n_estimators=150; total time=   6.3s\n",
            "[CV] END max_depth=10, min_samples_leaf=40, min_samples_split=50, n_estimators=150; total time=   6.3s\n",
            "[CV] END max_depth=10, min_samples_leaf=40, min_samples_split=50, n_estimators=150; total time=   6.3s\n",
            "[CV] END max_depth=10, min_samples_leaf=40, min_samples_split=50, n_estimators=200; total time=   8.4s\n",
            "[CV] END max_depth=10, min_samples_leaf=40, min_samples_split=50, n_estimators=200; total time=   8.4s\n",
            "[CV] END max_depth=10, min_samples_leaf=40, min_samples_split=50, n_estimators=200; total time=   8.3s\n",
            "[CV] END max_depth=10, min_samples_leaf=40, min_samples_split=50, n_estimators=200; total time=   8.2s\n",
            "[CV] END max_depth=10, min_samples_leaf=40, min_samples_split=50, n_estimators=200; total time=   8.2s\n",
            "[CV] END max_depth=10, min_samples_leaf=40, min_samples_split=100, n_estimators=100; total time=   4.2s\n",
            "[CV] END max_depth=10, min_samples_leaf=40, min_samples_split=100, n_estimators=100; total time=   4.2s\n",
            "[CV] END max_depth=10, min_samples_leaf=40, min_samples_split=100, n_estimators=100; total time=   4.2s\n",
            "[CV] END max_depth=10, min_samples_leaf=40, min_samples_split=100, n_estimators=100; total time=   4.2s\n",
            "[CV] END max_depth=10, min_samples_leaf=40, min_samples_split=100, n_estimators=100; total time=   4.1s\n",
            "[CV] END max_depth=10, min_samples_leaf=40, min_samples_split=100, n_estimators=150; total time=   6.2s\n",
            "[CV] END max_depth=10, min_samples_leaf=40, min_samples_split=100, n_estimators=150; total time=   6.2s\n",
            "[CV] END max_depth=10, min_samples_leaf=40, min_samples_split=100, n_estimators=150; total time=   6.3s\n",
            "[CV] END max_depth=10, min_samples_leaf=40, min_samples_split=100, n_estimators=150; total time=   6.2s\n",
            "[CV] END max_depth=10, min_samples_leaf=40, min_samples_split=100, n_estimators=150; total time=   6.2s\n",
            "[CV] END max_depth=10, min_samples_leaf=40, min_samples_split=100, n_estimators=200; total time=   8.3s\n",
            "[CV] END max_depth=10, min_samples_leaf=40, min_samples_split=100, n_estimators=200; total time=   8.3s\n",
            "[CV] END max_depth=10, min_samples_leaf=40, min_samples_split=100, n_estimators=200; total time=   8.4s\n",
            "[CV] END max_depth=10, min_samples_leaf=40, min_samples_split=100, n_estimators=200; total time=   8.2s\n",
            "[CV] END max_depth=10, min_samples_leaf=40, min_samples_split=100, n_estimators=200; total time=   8.1s\n",
            "[CV] END max_depth=10, min_samples_leaf=40, min_samples_split=150, n_estimators=100; total time=   4.1s\n",
            "[CV] END max_depth=10, min_samples_leaf=40, min_samples_split=150, n_estimators=100; total time=   4.0s\n",
            "[CV] END max_depth=10, min_samples_leaf=40, min_samples_split=150, n_estimators=100; total time=   4.0s\n",
            "[CV] END max_depth=10, min_samples_leaf=40, min_samples_split=150, n_estimators=100; total time=   4.0s\n",
            "[CV] END max_depth=10, min_samples_leaf=40, min_samples_split=150, n_estimators=100; total time=   4.1s\n",
            "[CV] END max_depth=10, min_samples_leaf=40, min_samples_split=150, n_estimators=150; total time=   6.1s\n",
            "[CV] END max_depth=10, min_samples_leaf=40, min_samples_split=150, n_estimators=150; total time=   6.1s\n",
            "[CV] END max_depth=10, min_samples_leaf=40, min_samples_split=150, n_estimators=150; total time=   6.1s\n",
            "[CV] END max_depth=10, min_samples_leaf=40, min_samples_split=150, n_estimators=150; total time=   6.0s\n",
            "[CV] END max_depth=10, min_samples_leaf=40, min_samples_split=150, n_estimators=150; total time=   6.2s\n",
            "[CV] END max_depth=10, min_samples_leaf=40, min_samples_split=150, n_estimators=200; total time=   8.1s\n",
            "[CV] END max_depth=10, min_samples_leaf=40, min_samples_split=150, n_estimators=200; total time=   8.1s\n",
            "[CV] END max_depth=10, min_samples_leaf=40, min_samples_split=150, n_estimators=200; total time=   8.1s\n",
            "[CV] END max_depth=10, min_samples_leaf=40, min_samples_split=150, n_estimators=200; total time=   8.0s\n",
            "[CV] END max_depth=10, min_samples_leaf=40, min_samples_split=150, n_estimators=200; total time=   8.2s\n",
            "[CV] END max_depth=10, min_samples_leaf=50, min_samples_split=50, n_estimators=100; total time=   4.1s\n",
            "[CV] END max_depth=10, min_samples_leaf=50, min_samples_split=50, n_estimators=100; total time=   4.1s\n",
            "[CV] END max_depth=10, min_samples_leaf=50, min_samples_split=50, n_estimators=100; total time=   4.0s\n",
            "[CV] END max_depth=10, min_samples_leaf=50, min_samples_split=50, n_estimators=100; total time=   4.0s\n",
            "[CV] END max_depth=10, min_samples_leaf=50, min_samples_split=50, n_estimators=100; total time=   4.0s\n",
            "[CV] END max_depth=10, min_samples_leaf=50, min_samples_split=50, n_estimators=150; total time=   6.1s\n",
            "[CV] END max_depth=10, min_samples_leaf=50, min_samples_split=50, n_estimators=150; total time=   6.1s\n",
            "[CV] END max_depth=10, min_samples_leaf=50, min_samples_split=50, n_estimators=150; total time=   6.3s\n",
            "[CV] END max_depth=10, min_samples_leaf=50, min_samples_split=50, n_estimators=150; total time=   6.2s\n",
            "[CV] END max_depth=10, min_samples_leaf=50, min_samples_split=50, n_estimators=150; total time=   6.0s\n",
            "[CV] END max_depth=10, min_samples_leaf=50, min_samples_split=50, n_estimators=200; total time=   8.0s\n",
            "[CV] END max_depth=10, min_samples_leaf=50, min_samples_split=50, n_estimators=200; total time=   8.1s\n",
            "[CV] END max_depth=10, min_samples_leaf=50, min_samples_split=50, n_estimators=200; total time=   8.1s\n",
            "[CV] END max_depth=10, min_samples_leaf=50, min_samples_split=50, n_estimators=200; total time=   8.0s\n",
            "[CV] END max_depth=10, min_samples_leaf=50, min_samples_split=50, n_estimators=200; total time=   8.2s\n",
            "[CV] END max_depth=10, min_samples_leaf=50, min_samples_split=100, n_estimators=100; total time=   4.0s\n",
            "[CV] END max_depth=10, min_samples_leaf=50, min_samples_split=100, n_estimators=100; total time=   4.1s\n",
            "[CV] END max_depth=10, min_samples_leaf=50, min_samples_split=100, n_estimators=100; total time=   4.1s\n",
            "[CV] END max_depth=10, min_samples_leaf=50, min_samples_split=100, n_estimators=100; total time=   4.1s\n",
            "[CV] END max_depth=10, min_samples_leaf=50, min_samples_split=100, n_estimators=100; total time=   4.1s\n",
            "[CV] END max_depth=10, min_samples_leaf=50, min_samples_split=100, n_estimators=150; total time=   6.1s\n",
            "[CV] END max_depth=10, min_samples_leaf=50, min_samples_split=100, n_estimators=150; total time=   6.1s\n",
            "[CV] END max_depth=10, min_samples_leaf=50, min_samples_split=100, n_estimators=150; total time=   6.1s\n",
            "[CV] END max_depth=10, min_samples_leaf=50, min_samples_split=100, n_estimators=150; total time=   6.1s\n",
            "[CV] END max_depth=10, min_samples_leaf=50, min_samples_split=100, n_estimators=150; total time=   6.1s\n",
            "[CV] END max_depth=10, min_samples_leaf=50, min_samples_split=100, n_estimators=200; total time=   8.1s\n",
            "[CV] END max_depth=10, min_samples_leaf=50, min_samples_split=100, n_estimators=200; total time=   8.0s\n",
            "[CV] END max_depth=10, min_samples_leaf=50, min_samples_split=100, n_estimators=200; total time=   8.0s\n",
            "[CV] END max_depth=10, min_samples_leaf=50, min_samples_split=100, n_estimators=200; total time=   8.0s\n",
            "[CV] END max_depth=10, min_samples_leaf=50, min_samples_split=100, n_estimators=200; total time=   8.1s\n",
            "[CV] END max_depth=10, min_samples_leaf=50, min_samples_split=150, n_estimators=100; total time=   4.0s\n",
            "[CV] END max_depth=10, min_samples_leaf=50, min_samples_split=150, n_estimators=100; total time=   4.0s\n",
            "[CV] END max_depth=10, min_samples_leaf=50, min_samples_split=150, n_estimators=100; total time=   4.0s\n",
            "[CV] END max_depth=10, min_samples_leaf=50, min_samples_split=150, n_estimators=100; total time=   4.0s\n",
            "[CV] END max_depth=10, min_samples_leaf=50, min_samples_split=150, n_estimators=100; total time=   4.0s\n",
            "[CV] END max_depth=10, min_samples_leaf=50, min_samples_split=150, n_estimators=150; total time=   6.1s\n",
            "[CV] END max_depth=10, min_samples_leaf=50, min_samples_split=150, n_estimators=150; total time=   6.1s\n",
            "[CV] END max_depth=10, min_samples_leaf=50, min_samples_split=150, n_estimators=150; total time=   5.9s\n",
            "[CV] END max_depth=10, min_samples_leaf=50, min_samples_split=150, n_estimators=150; total time=   6.0s\n",
            "[CV] END max_depth=10, min_samples_leaf=50, min_samples_split=150, n_estimators=150; total time=   6.0s\n",
            "[CV] END max_depth=10, min_samples_leaf=50, min_samples_split=150, n_estimators=200; total time=   8.1s\n",
            "[CV] END max_depth=10, min_samples_leaf=50, min_samples_split=150, n_estimators=200; total time=   8.0s\n",
            "[CV] END max_depth=10, min_samples_leaf=50, min_samples_split=150, n_estimators=200; total time=   7.9s\n",
            "[CV] END max_depth=10, min_samples_leaf=50, min_samples_split=150, n_estimators=200; total time=   8.0s\n",
            "[CV] END max_depth=10, min_samples_leaf=50, min_samples_split=150, n_estimators=200; total time=   8.4s\n",
            "[CV] END max_depth=20, min_samples_leaf=40, min_samples_split=50, n_estimators=100; total time=   4.4s\n",
            "[CV] END max_depth=20, min_samples_leaf=40, min_samples_split=50, n_estimators=100; total time=   4.5s\n",
            "[CV] END max_depth=20, min_samples_leaf=40, min_samples_split=50, n_estimators=100; total time=   4.5s\n",
            "[CV] END max_depth=20, min_samples_leaf=40, min_samples_split=50, n_estimators=100; total time=   4.5s\n",
            "[CV] END max_depth=20, min_samples_leaf=40, min_samples_split=50, n_estimators=100; total time=   4.5s\n",
            "[CV] END max_depth=20, min_samples_leaf=40, min_samples_split=50, n_estimators=150; total time=   6.8s\n",
            "[CV] END max_depth=20, min_samples_leaf=40, min_samples_split=50, n_estimators=150; total time=   6.7s\n",
            "[CV] END max_depth=20, min_samples_leaf=40, min_samples_split=50, n_estimators=150; total time=   6.8s\n",
            "[CV] END max_depth=20, min_samples_leaf=40, min_samples_split=50, n_estimators=150; total time=   6.3s\n",
            "[CV] END max_depth=20, min_samples_leaf=40, min_samples_split=50, n_estimators=150; total time=   6.4s\n",
            "[CV] END max_depth=20, min_samples_leaf=40, min_samples_split=50, n_estimators=200; total time=   8.5s\n",
            "[CV] END max_depth=20, min_samples_leaf=40, min_samples_split=50, n_estimators=200; total time=   8.6s\n",
            "[CV] END max_depth=20, min_samples_leaf=40, min_samples_split=50, n_estimators=200; total time=   8.5s\n",
            "[CV] END max_depth=20, min_samples_leaf=40, min_samples_split=50, n_estimators=200; total time=   8.6s\n",
            "[CV] END max_depth=20, min_samples_leaf=40, min_samples_split=50, n_estimators=200; total time=   8.6s\n",
            "[CV] END max_depth=20, min_samples_leaf=40, min_samples_split=100, n_estimators=100; total time=   4.2s\n",
            "[CV] END max_depth=20, min_samples_leaf=40, min_samples_split=100, n_estimators=100; total time=   4.2s\n",
            "[CV] END max_depth=20, min_samples_leaf=40, min_samples_split=100, n_estimators=100; total time=   4.2s\n",
            "[CV] END max_depth=20, min_samples_leaf=40, min_samples_split=100, n_estimators=100; total time=   4.3s\n",
            "[CV] END max_depth=20, min_samples_leaf=40, min_samples_split=100, n_estimators=100; total time=   4.2s\n",
            "[CV] END max_depth=20, min_samples_leaf=40, min_samples_split=100, n_estimators=150; total time=   6.3s\n",
            "[CV] END max_depth=20, min_samples_leaf=40, min_samples_split=100, n_estimators=150; total time=   6.3s\n",
            "[CV] END max_depth=20, min_samples_leaf=40, min_samples_split=100, n_estimators=150; total time=   6.3s\n",
            "[CV] END max_depth=20, min_samples_leaf=40, min_samples_split=100, n_estimators=150; total time=   6.2s\n",
            "[CV] END max_depth=20, min_samples_leaf=40, min_samples_split=100, n_estimators=150; total time=   6.4s\n",
            "[CV] END max_depth=20, min_samples_leaf=40, min_samples_split=100, n_estimators=200; total time=   8.4s\n",
            "[CV] END max_depth=20, min_samples_leaf=40, min_samples_split=100, n_estimators=200; total time=   8.4s\n",
            "[CV] END max_depth=20, min_samples_leaf=40, min_samples_split=100, n_estimators=200; total time=   8.5s\n",
            "[CV] END max_depth=20, min_samples_leaf=40, min_samples_split=100, n_estimators=200; total time=   8.4s\n",
            "[CV] END max_depth=20, min_samples_leaf=40, min_samples_split=100, n_estimators=200; total time=   8.6s\n",
            "[CV] END max_depth=20, min_samples_leaf=40, min_samples_split=150, n_estimators=100; total time=   4.1s\n",
            "[CV] END max_depth=20, min_samples_leaf=40, min_samples_split=150, n_estimators=100; total time=   4.1s\n",
            "[CV] END max_depth=20, min_samples_leaf=40, min_samples_split=150, n_estimators=100; total time=   4.1s\n",
            "[CV] END max_depth=20, min_samples_leaf=40, min_samples_split=150, n_estimators=100; total time=   4.2s\n",
            "[CV] END max_depth=20, min_samples_leaf=40, min_samples_split=150, n_estimators=100; total time=   4.1s\n",
            "[CV] END max_depth=20, min_samples_leaf=40, min_samples_split=150, n_estimators=150; total time=   6.1s\n",
            "[CV] END max_depth=20, min_samples_leaf=40, min_samples_split=150, n_estimators=150; total time=   6.1s\n",
            "[CV] END max_depth=20, min_samples_leaf=40, min_samples_split=150, n_estimators=150; total time=   6.2s\n",
            "[CV] END max_depth=20, min_samples_leaf=40, min_samples_split=150, n_estimators=150; total time=   6.1s\n",
            "[CV] END max_depth=20, min_samples_leaf=40, min_samples_split=150, n_estimators=150; total time=   6.2s\n",
            "[CV] END max_depth=20, min_samples_leaf=40, min_samples_split=150, n_estimators=200; total time=   8.3s\n",
            "[CV] END max_depth=20, min_samples_leaf=40, min_samples_split=150, n_estimators=200; total time=   8.1s\n",
            "[CV] END max_depth=20, min_samples_leaf=40, min_samples_split=150, n_estimators=200; total time=   8.2s\n",
            "[CV] END max_depth=20, min_samples_leaf=40, min_samples_split=150, n_estimators=200; total time=   8.3s\n",
            "[CV] END max_depth=20, min_samples_leaf=40, min_samples_split=150, n_estimators=200; total time=   8.2s\n",
            "[CV] END max_depth=20, min_samples_leaf=50, min_samples_split=50, n_estimators=100; total time=   4.2s\n",
            "[CV] END max_depth=20, min_samples_leaf=50, min_samples_split=50, n_estimators=100; total time=   4.1s\n",
            "[CV] END max_depth=20, min_samples_leaf=50, min_samples_split=50, n_estimators=100; total time=   4.2s\n",
            "[CV] END max_depth=20, min_samples_leaf=50, min_samples_split=50, n_estimators=100; total time=   4.1s\n",
            "[CV] END max_depth=20, min_samples_leaf=50, min_samples_split=50, n_estimators=100; total time=   4.1s\n",
            "[CV] END max_depth=20, min_samples_leaf=50, min_samples_split=50, n_estimators=150; total time=   6.3s\n",
            "[CV] END max_depth=20, min_samples_leaf=50, min_samples_split=50, n_estimators=150; total time=   6.2s\n",
            "[CV] END max_depth=20, min_samples_leaf=50, min_samples_split=50, n_estimators=150; total time=   6.2s\n",
            "[CV] END max_depth=20, min_samples_leaf=50, min_samples_split=50, n_estimators=150; total time=   6.2s\n",
            "[CV] END max_depth=20, min_samples_leaf=50, min_samples_split=50, n_estimators=150; total time=   6.3s\n",
            "[CV] END max_depth=20, min_samples_leaf=50, min_samples_split=50, n_estimators=200; total time=   8.3s\n",
            "[CV] END max_depth=20, min_samples_leaf=50, min_samples_split=50, n_estimators=200; total time=   8.2s\n",
            "[CV] END max_depth=20, min_samples_leaf=50, min_samples_split=50, n_estimators=200; total time=   8.3s\n",
            "[CV] END max_depth=20, min_samples_leaf=50, min_samples_split=50, n_estimators=200; total time=   8.2s\n",
            "[CV] END max_depth=20, min_samples_leaf=50, min_samples_split=50, n_estimators=200; total time=   8.3s\n",
            "[CV] END max_depth=20, min_samples_leaf=50, min_samples_split=100, n_estimators=100; total time=   4.2s\n",
            "[CV] END max_depth=20, min_samples_leaf=50, min_samples_split=100, n_estimators=100; total time=   4.1s\n",
            "[CV] END max_depth=20, min_samples_leaf=50, min_samples_split=100, n_estimators=100; total time=   4.2s\n",
            "[CV] END max_depth=20, min_samples_leaf=50, min_samples_split=100, n_estimators=100; total time=   4.1s\n",
            "[CV] END max_depth=20, min_samples_leaf=50, min_samples_split=100, n_estimators=100; total time=   4.2s\n",
            "[CV] END max_depth=20, min_samples_leaf=50, min_samples_split=100, n_estimators=150; total time=   6.2s\n",
            "[CV] END max_depth=20, min_samples_leaf=50, min_samples_split=100, n_estimators=150; total time=   6.3s\n",
            "[CV] END max_depth=20, min_samples_leaf=50, min_samples_split=100, n_estimators=150; total time=   6.2s\n",
            "[CV] END max_depth=20, min_samples_leaf=50, min_samples_split=100, n_estimators=150; total time=   6.2s\n",
            "[CV] END max_depth=20, min_samples_leaf=50, min_samples_split=100, n_estimators=150; total time=   6.2s\n",
            "[CV] END max_depth=20, min_samples_leaf=50, min_samples_split=100, n_estimators=200; total time=   8.3s\n",
            "[CV] END max_depth=20, min_samples_leaf=50, min_samples_split=100, n_estimators=200; total time=   8.3s\n",
            "[CV] END max_depth=20, min_samples_leaf=50, min_samples_split=100, n_estimators=200; total time=   8.3s\n",
            "[CV] END max_depth=20, min_samples_leaf=50, min_samples_split=100, n_estimators=200; total time=   8.3s\n",
            "[CV] END max_depth=20, min_samples_leaf=50, min_samples_split=100, n_estimators=200; total time=   8.2s\n",
            "[CV] END max_depth=20, min_samples_leaf=50, min_samples_split=150, n_estimators=100; total time=   4.0s\n",
            "[CV] END max_depth=20, min_samples_leaf=50, min_samples_split=150, n_estimators=100; total time=   4.1s\n",
            "[CV] END max_depth=20, min_samples_leaf=50, min_samples_split=150, n_estimators=100; total time=   4.0s\n",
            "[CV] END max_depth=20, min_samples_leaf=50, min_samples_split=150, n_estimators=100; total time=   4.1s\n",
            "[CV] END max_depth=20, min_samples_leaf=50, min_samples_split=150, n_estimators=100; total time=   4.1s\n",
            "[CV] END max_depth=20, min_samples_leaf=50, min_samples_split=150, n_estimators=150; total time=   6.0s\n",
            "[CV] END max_depth=20, min_samples_leaf=50, min_samples_split=150, n_estimators=150; total time=   6.1s\n",
            "[CV] END max_depth=20, min_samples_leaf=50, min_samples_split=150, n_estimators=150; total time=   6.0s\n",
            "[CV] END max_depth=20, min_samples_leaf=50, min_samples_split=150, n_estimators=150; total time=   6.0s\n",
            "[CV] END max_depth=20, min_samples_leaf=50, min_samples_split=150, n_estimators=150; total time=   6.0s\n",
            "[CV] END max_depth=20, min_samples_leaf=50, min_samples_split=150, n_estimators=200; total time=   8.0s\n",
            "[CV] END max_depth=20, min_samples_leaf=50, min_samples_split=150, n_estimators=200; total time=   8.1s\n",
            "[CV] END max_depth=20, min_samples_leaf=50, min_samples_split=150, n_estimators=200; total time=   8.2s\n",
            "[CV] END max_depth=20, min_samples_leaf=50, min_samples_split=150, n_estimators=200; total time=   8.0s\n",
            "[CV] END max_depth=20, min_samples_leaf=50, min_samples_split=150, n_estimators=200; total time=   8.0s\n",
            "[CV] END max_depth=30, min_samples_leaf=40, min_samples_split=50, n_estimators=100; total time=   4.2s\n",
            "[CV] END max_depth=30, min_samples_leaf=40, min_samples_split=50, n_estimators=100; total time=   4.2s\n",
            "[CV] END max_depth=30, min_samples_leaf=40, min_samples_split=50, n_estimators=100; total time=   4.3s\n",
            "[CV] END max_depth=30, min_samples_leaf=40, min_samples_split=50, n_estimators=100; total time=   4.3s\n",
            "[CV] END max_depth=30, min_samples_leaf=40, min_samples_split=50, n_estimators=100; total time=   4.2s\n",
            "[CV] END max_depth=30, min_samples_leaf=40, min_samples_split=50, n_estimators=150; total time=   6.4s\n",
            "[CV] END max_depth=30, min_samples_leaf=40, min_samples_split=50, n_estimators=150; total time=   6.3s\n",
            "[CV] END max_depth=30, min_samples_leaf=40, min_samples_split=50, n_estimators=150; total time=   6.5s\n",
            "[CV] END max_depth=30, min_samples_leaf=40, min_samples_split=50, n_estimators=150; total time=   6.3s\n",
            "[CV] END max_depth=30, min_samples_leaf=40, min_samples_split=50, n_estimators=150; total time=   6.4s\n",
            "[CV] END max_depth=30, min_samples_leaf=40, min_samples_split=50, n_estimators=200; total time=   8.4s\n",
            "[CV] END max_depth=30, min_samples_leaf=40, min_samples_split=50, n_estimators=200; total time=   8.5s\n",
            "[CV] END max_depth=30, min_samples_leaf=40, min_samples_split=50, n_estimators=200; total time=   8.6s\n",
            "[CV] END max_depth=30, min_samples_leaf=40, min_samples_split=50, n_estimators=200; total time=   8.5s\n",
            "[CV] END max_depth=30, min_samples_leaf=40, min_samples_split=50, n_estimators=200; total time=   8.6s\n",
            "[CV] END max_depth=30, min_samples_leaf=40, min_samples_split=100, n_estimators=100; total time=   4.2s\n",
            "[CV] END max_depth=30, min_samples_leaf=40, min_samples_split=100, n_estimators=100; total time=   4.2s\n",
            "[CV] END max_depth=30, min_samples_leaf=40, min_samples_split=100, n_estimators=100; total time=   4.2s\n",
            "[CV] END max_depth=30, min_samples_leaf=40, min_samples_split=100, n_estimators=100; total time=   4.3s\n",
            "[CV] END max_depth=30, min_samples_leaf=40, min_samples_split=100, n_estimators=100; total time=   4.2s\n",
            "[CV] END max_depth=30, min_samples_leaf=40, min_samples_split=100, n_estimators=150; total time=   6.4s\n",
            "[CV] END max_depth=30, min_samples_leaf=40, min_samples_split=100, n_estimators=150; total time=   6.3s\n",
            "[CV] END max_depth=30, min_samples_leaf=40, min_samples_split=100, n_estimators=150; total time=   6.3s\n",
            "[CV] END max_depth=30, min_samples_leaf=40, min_samples_split=100, n_estimators=150; total time=   6.3s\n",
            "[CV] END max_depth=30, min_samples_leaf=40, min_samples_split=100, n_estimators=150; total time=   6.2s\n",
            "[CV] END max_depth=30, min_samples_leaf=40, min_samples_split=100, n_estimators=200; total time=   8.4s\n",
            "[CV] END max_depth=30, min_samples_leaf=40, min_samples_split=100, n_estimators=200; total time=   8.4s\n",
            "[CV] END max_depth=30, min_samples_leaf=40, min_samples_split=100, n_estimators=200; total time=   8.3s\n",
            "[CV] END max_depth=30, min_samples_leaf=40, min_samples_split=100, n_estimators=200; total time=   8.3s\n",
            "[CV] END max_depth=30, min_samples_leaf=40, min_samples_split=100, n_estimators=200; total time=   8.5s\n",
            "[CV] END max_depth=30, min_samples_leaf=40, min_samples_split=150, n_estimators=100; total time=   4.1s\n",
            "[CV] END max_depth=30, min_samples_leaf=40, min_samples_split=150, n_estimators=100; total time=   4.1s\n",
            "[CV] END max_depth=30, min_samples_leaf=40, min_samples_split=150, n_estimators=100; total time=   4.2s\n",
            "[CV] END max_depth=30, min_samples_leaf=40, min_samples_split=150, n_estimators=100; total time=   4.1s\n",
            "[CV] END max_depth=30, min_samples_leaf=40, min_samples_split=150, n_estimators=100; total time=   4.1s\n",
            "[CV] END max_depth=30, min_samples_leaf=40, min_samples_split=150, n_estimators=150; total time=   6.2s\n",
            "[CV] END max_depth=30, min_samples_leaf=40, min_samples_split=150, n_estimators=150; total time=   6.1s\n",
            "[CV] END max_depth=30, min_samples_leaf=40, min_samples_split=150, n_estimators=150; total time=   6.3s\n",
            "[CV] END max_depth=30, min_samples_leaf=40, min_samples_split=150, n_estimators=150; total time=   6.2s\n",
            "[CV] END max_depth=30, min_samples_leaf=40, min_samples_split=150, n_estimators=150; total time=   6.1s\n",
            "[CV] END max_depth=30, min_samples_leaf=40, min_samples_split=150, n_estimators=200; total time=   8.2s\n",
            "[CV] END max_depth=30, min_samples_leaf=40, min_samples_split=150, n_estimators=200; total time=   8.2s\n",
            "[CV] END max_depth=30, min_samples_leaf=40, min_samples_split=150, n_estimators=200; total time=   8.2s\n",
            "[CV] END max_depth=30, min_samples_leaf=40, min_samples_split=150, n_estimators=200; total time=   8.1s\n",
            "[CV] END max_depth=30, min_samples_leaf=40, min_samples_split=150, n_estimators=200; total time=   8.2s\n",
            "[CV] END max_depth=30, min_samples_leaf=50, min_samples_split=50, n_estimators=100; total time=   4.1s\n",
            "[CV] END max_depth=30, min_samples_leaf=50, min_samples_split=50, n_estimators=100; total time=   4.1s\n",
            "[CV] END max_depth=30, min_samples_leaf=50, min_samples_split=50, n_estimators=100; total time=   4.1s\n",
            "[CV] END max_depth=30, min_samples_leaf=50, min_samples_split=50, n_estimators=100; total time=   4.1s\n",
            "[CV] END max_depth=30, min_samples_leaf=50, min_samples_split=50, n_estimators=100; total time=   4.1s\n",
            "[CV] END max_depth=30, min_samples_leaf=50, min_samples_split=50, n_estimators=150; total time=   6.2s\n",
            "[CV] END max_depth=30, min_samples_leaf=50, min_samples_split=50, n_estimators=150; total time=   6.2s\n",
            "[CV] END max_depth=30, min_samples_leaf=50, min_samples_split=50, n_estimators=150; total time=   6.1s\n",
            "[CV] END max_depth=30, min_samples_leaf=50, min_samples_split=50, n_estimators=150; total time=   6.2s\n",
            "[CV] END max_depth=30, min_samples_leaf=50, min_samples_split=50, n_estimators=150; total time=   6.2s\n",
            "[CV] END max_depth=30, min_samples_leaf=50, min_samples_split=50, n_estimators=200; total time=   8.2s\n",
            "[CV] END max_depth=30, min_samples_leaf=50, min_samples_split=50, n_estimators=200; total time=   8.2s\n",
            "[CV] END max_depth=30, min_samples_leaf=50, min_samples_split=50, n_estimators=200; total time=   8.2s\n",
            "[CV] END max_depth=30, min_samples_leaf=50, min_samples_split=50, n_estimators=200; total time=   8.2s\n",
            "[CV] END max_depth=30, min_samples_leaf=50, min_samples_split=50, n_estimators=200; total time=   8.3s\n",
            "[CV] END max_depth=30, min_samples_leaf=50, min_samples_split=100, n_estimators=100; total time=   4.1s\n",
            "[CV] END max_depth=30, min_samples_leaf=50, min_samples_split=100, n_estimators=100; total time=   4.1s\n",
            "[CV] END max_depth=30, min_samples_leaf=50, min_samples_split=100, n_estimators=100; total time=   4.1s\n",
            "[CV] END max_depth=30, min_samples_leaf=50, min_samples_split=100, n_estimators=100; total time=   4.0s\n",
            "[CV] END max_depth=30, min_samples_leaf=50, min_samples_split=100, n_estimators=100; total time=   4.2s\n",
            "[CV] END max_depth=30, min_samples_leaf=50, min_samples_split=100, n_estimators=150; total time=   6.1s\n",
            "[CV] END max_depth=30, min_samples_leaf=50, min_samples_split=100, n_estimators=150; total time=   6.1s\n",
            "[CV] END max_depth=30, min_samples_leaf=50, min_samples_split=100, n_estimators=150; total time=   6.1s\n",
            "[CV] END max_depth=30, min_samples_leaf=50, min_samples_split=100, n_estimators=150; total time=   6.2s\n",
            "[CV] END max_depth=30, min_samples_leaf=50, min_samples_split=100, n_estimators=150; total time=   6.2s\n",
            "[CV] END max_depth=30, min_samples_leaf=50, min_samples_split=100, n_estimators=200; total time=   8.2s\n",
            "[CV] END max_depth=30, min_samples_leaf=50, min_samples_split=100, n_estimators=200; total time=   8.2s\n",
            "[CV] END max_depth=30, min_samples_leaf=50, min_samples_split=100, n_estimators=200; total time=   8.2s\n",
            "[CV] END max_depth=30, min_samples_leaf=50, min_samples_split=100, n_estimators=200; total time=   8.3s\n",
            "[CV] END max_depth=30, min_samples_leaf=50, min_samples_split=100, n_estimators=200; total time=   8.1s\n",
            "[CV] END max_depth=30, min_samples_leaf=50, min_samples_split=150, n_estimators=100; total time=   4.1s\n",
            "[CV] END max_depth=30, min_samples_leaf=50, min_samples_split=150, n_estimators=100; total time=   4.1s\n",
            "[CV] END max_depth=30, min_samples_leaf=50, min_samples_split=150, n_estimators=100; total time=   4.1s\n",
            "[CV] END max_depth=30, min_samples_leaf=50, min_samples_split=150, n_estimators=100; total time=   4.0s\n",
            "[CV] END max_depth=30, min_samples_leaf=50, min_samples_split=150, n_estimators=100; total time=   4.0s\n",
            "[CV] END max_depth=30, min_samples_leaf=50, min_samples_split=150, n_estimators=150; total time=   6.1s\n",
            "[CV] END max_depth=30, min_samples_leaf=50, min_samples_split=150, n_estimators=150; total time=   6.0s\n",
            "[CV] END max_depth=30, min_samples_leaf=50, min_samples_split=150, n_estimators=150; total time=   5.9s\n",
            "[CV] END max_depth=30, min_samples_leaf=50, min_samples_split=150, n_estimators=150; total time=   6.0s\n",
            "[CV] END max_depth=30, min_samples_leaf=50, min_samples_split=150, n_estimators=150; total time=   6.0s\n",
            "[CV] END max_depth=30, min_samples_leaf=50, min_samples_split=150, n_estimators=200; total time=   7.9s\n",
            "[CV] END max_depth=30, min_samples_leaf=50, min_samples_split=150, n_estimators=200; total time=   8.0s\n",
            "[CV] END max_depth=30, min_samples_leaf=50, min_samples_split=150, n_estimators=200; total time=   8.1s\n",
            "[CV] END max_depth=30, min_samples_leaf=50, min_samples_split=150, n_estimators=200; total time=   8.1s\n",
            "[CV] END max_depth=30, min_samples_leaf=50, min_samples_split=150, n_estimators=200; total time=   8.2s\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
              "             param_grid={'max_depth': [10, 20, 30],\n",
              "                         'min_samples_leaf': [40, 50],\n",
              "                         'min_samples_split': [50, 100, 150],\n",
              "                         'n_estimators': [100, 150, 200]},\n",
              "             scoring='roc_auc', verbose=2)"
            ]
          },
          "execution_count": 334,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create an instance of the RandomForestClassifier\n",
        "rfc = RandomForestClassifier()\n",
        "\n",
        "# Grid search\n",
        "rfc_grid = GridSearchCV(estimator=rfc,\n",
        "                       param_grid = param_dict,\n",
        "                       cv = 5, verbose=2, scoring='roc_auc')\n",
        "# fitting model\n",
        "rfc_grid.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfcQ7wTpJf1t",
        "outputId": "9ab8fd75-b771-445b-82af-f1711b4e7318"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RandomForestClassifier(max_depth=30, min_samples_leaf=40, min_samples_split=50)"
            ]
          },
          "execution_count": 335,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rfc_grid.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYOUV0r_Jlo3",
        "outputId": "1f2a1deb-8629-4eae-c0dd-5d6e34b871cb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'max_depth': 30,\n",
              " 'min_samples_leaf': 40,\n",
              " 'min_samples_split': 50,\n",
              " 'n_estimators': 100}"
            ]
          },
          "execution_count": 336,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rfc_grid.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fEz3MdncJfyw"
      },
      "outputs": [],
      "source": [
        "rfc_optimal_model = rfc_grid.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "cF2r3W_zJfvr"
      },
      "outputs": [],
      "source": [
        "#class prediction of y on train and test\n",
        "y_pred_rfc_grid=rfc_optimal_model.predict(X_test)\n",
        "y_train_pred_rfc_grid=rfc_optimal_model.predict(X_train)\n",
        "\n",
        "# Get the probabilities on train and test\n",
        "y_pred_prob_rfc_grid = rfc_optimal_model.predict_proba(X_train)[:,1]\n",
        "y_train_pred_prob_rfc_grid = rfc_optimal_model.predict_proba(X_test)[:,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "pAoDDAhyJfsw",
        "outputId": "c48939c3-ba0f-4364-f75e-0a71092d45a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The accuracy on train data is  0.844\n",
            "The accuracy on test data is  0.833\n",
            "The precision on test data is  0.794\n",
            "The recall on test data is  0.861\n",
            "The f1 on test data is  0.826\n",
            "The auc on test data is  0.835\n"
          ]
        }
      ],
      "source": [
        "#getting all scores for Random Forest Classifier after CV and Hyperparameter Tunning\n",
        "train_accuracy_rfc_grid = round(accuracy_score(y_train_pred_rfc_grid,y_train), 3)\n",
        "accuracy_rfc_grid = round(accuracy_score(y_pred_rfc_grid,y_test), 3)\n",
        "precision_score_rfc_grid = round(precision_score(y_pred_rfc_grid,y_test), 3)\n",
        "recall_score_rfc_grid = round(recall_score(y_pred_rfc_grid,y_test), 3)\n",
        "f1_score_rfc_grid = round(f1_score(y_pred_rfc_grid,y_test), 3)\n",
        "auc_rfc_grid = round(roc_auc_score(y_pred_rfc_grid,y_test), 3)\n",
        "\n",
        "print(\"The accuracy on train data is \", train_accuracy_rfc_grid)\n",
        "print(\"The accuracy on test data is \", accuracy_rfc_grid)\n",
        "print(\"The precision on test data is \", precision_score_rfc_grid)\n",
        "print(\"The recall on test data is \", recall_score_rfc_grid)\n",
        "print(\"The f1 on test data is \", f1_score_rfc_grid)\n",
        "print(\"The auc on test data is \", auc_rfc_grid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "tlQ3NPZ0Jfpu"
      },
      "outputs": [],
      "source": [
        "# Get the confusion matrices for train and test\n",
        "train_cm_rfc_grid = confusion_matrix(y_train,y_train_pred_rfc_grid)\n",
        "test_cm_rfc_grid = confusion_matrix(y_test,y_pred_rfc_grid )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "8j5zEzqb6E0c",
        "outputId": "594ffb3f-88db-4205-d3e1-637829738c6b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[16570,  2121],\n",
              "       [ 3720, 14971]])"
            ]
          },
          "execution_count": 341,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_cm_rfc_grid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIiDJagg6F7V",
        "outputId": "1c2fa530-c002-45e1-8836-8a5c7a239afc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[4073,  600],\n",
              "       [ 963, 3710]])"
            ]
          },
          "execution_count": 342,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_cm_rfc_grid"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYFTO_WbNhKg"
      },
      "source": [
        "## **Gradient Boosting**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fTt0ddvDeHe2"
      },
      "outputs": [],
      "source": [
        "# to shrinks the contribution of each tree by learning_rate\n",
        "learning_rates = [1, 0.5, 0.25, 0.1, 0.05, 0.01]\n",
        "\n",
        "# Number of trees\n",
        "n_estimators = [100,150,200]\n",
        "\n",
        "# Maximum depth of trees\n",
        "max_depth = [10,20,30]\n",
        "\n",
        "# Minimum number of samples required to split a node\n",
        "min_samples_split = [50,100,150]\n",
        "\n",
        "# Minimum number of samples required at each leaf node\n",
        "min_samples_leaf = [40,50]\n",
        "\n",
        "# Hyperparameter Grid\n",
        "param_dict = {'learning_rate': learning_rates,\n",
        "              'n_estimators' : n_estimators,\n",
        "              'max_depth' : max_depth,\n",
        "              'min_samples_split' : min_samples_split,\n",
        "              'min_samples_leaf' : min_samples_leaf}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8MSlw_0eHe3",
        "outputId": "fb1e6a5f-5a5c-4c6c-e761-f21c74489bfc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n",
            "[CV] END learning_rate=0.05, max_depth=30, min_samples_leaf=40, min_samples_split=50, n_estimators=150; total time= 1.1min\n",
            "[CV] END learning_rate=0.05, max_depth=30, min_samples_leaf=40, min_samples_split=50, n_estimators=150; total time= 1.1min\n",
            "[CV] END learning_rate=0.01, max_depth=30, min_samples_leaf=40, min_samples_split=150, n_estimators=100; total time=  30.9s\n",
            "[CV] END learning_rate=0.01, max_depth=30, min_samples_leaf=40, min_samples_split=150, n_estimators=100; total time=  31.1s\n",
            "[CV] END learning_rate=0.01, max_depth=10, min_samples_leaf=50, min_samples_split=150, n_estimators=200; total time=  49.9s\n",
            "[CV] END learning_rate=0.01, max_depth=10, min_samples_leaf=50, min_samples_split=150, n_estimators=200; total time=  50.5s\n",
            "[CV] END learning_rate=0.5, max_depth=10, min_samples_leaf=50, min_samples_split=150, n_estimators=150; total time=  44.4s\n",
            "[CV] END learning_rate=0.5, max_depth=10, min_samples_leaf=50, min_samples_split=150, n_estimators=150; total time=  43.7s\n",
            "[CV] END learning_rate=0.5, max_depth=20, min_samples_leaf=50, min_samples_split=150, n_estimators=200; total time= 1.6min\n",
            "[CV] END learning_rate=0.5, max_depth=20, min_samples_leaf=50, min_samples_split=150, n_estimators=200; total time= 1.5min\n",
            "[CV] END learning_rate=1, max_depth=30, min_samples_leaf=50, min_samples_split=100, n_estimators=200; total time= 1.9min\n",
            "[CV] END learning_rate=1, max_depth=30, min_samples_leaf=50, min_samples_split=100, n_estimators=200; total time= 1.9min\n",
            "[CV] END learning_rate=0.05, max_depth=10, min_samples_leaf=40, min_samples_split=100, n_estimators=100; total time=  26.8s\n",
            "[CV] END learning_rate=0.05, max_depth=10, min_samples_leaf=40, min_samples_split=100, n_estimators=100; total time=  26.9s\n",
            "[CV] END learning_rate=0.1, max_depth=10, min_samples_leaf=50, min_samples_split=100, n_estimators=100; total time=  28.4s\n",
            "[CV] END learning_rate=0.1, max_depth=10, min_samples_leaf=50, min_samples_split=100, n_estimators=100; total time=  28.1s\n",
            "[CV] END learning_rate=0.1, max_depth=30, min_samples_leaf=40, min_samples_split=150, n_estimators=200; total time= 1.8min\n",
            "[CV] END learning_rate=0.1, max_depth=30, min_samples_leaf=40, min_samples_split=150, n_estimators=200; total time= 1.8min\n",
            "[CV] END learning_rate=0.25, max_depth=20, min_samples_leaf=40, min_samples_split=100, n_estimators=150; total time= 1.1min\n",
            "[CV] END learning_rate=0.25, max_depth=20, min_samples_leaf=40, min_samples_split=100, n_estimators=150; total time= 1.1min\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=2, estimator=GradientBoostingClassifier(random_state=42),\n",
              "                   param_distributions={'learning_rate': [1, 0.5, 0.25, 0.1,\n",
              "                                                          0.05, 0.01],\n",
              "                                        'max_depth': [10, 20, 30],\n",
              "                                        'min_samples_leaf': [40, 50],\n",
              "                                        'min_samples_split': [50, 100, 150],\n",
              "                                        'n_estimators': [100, 150, 200]},\n",
              "                   scoring='roc_auc', verbose=2)"
            ]
          },
          "execution_count": 344,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create an instance of the RandomForestClassifier\n",
        "gbc = GradientBoostingClassifier(random_state=42)\n",
        "\n",
        "# Grid search\n",
        "gbc_grid = RandomizedSearchCV(estimator=gbc,\n",
        "                       param_distributions = param_dict,\n",
        "                       cv = 2, verbose=2, scoring='roc_auc')\n",
        "# fitting model\n",
        "gbc_grid.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVRxGR_-eHe4",
        "outputId": "72a79065-6c4a-49d4-af8d-d847fdf06943"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "GradientBoostingClassifier(learning_rate=0.05, max_depth=30,\n",
              "                           min_samples_leaf=40, min_samples_split=50,\n",
              "                           n_estimators=150, random_state=42)"
            ]
          },
          "execution_count": 345,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gbc_grid.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRSOAKnheHe4",
        "outputId": "8abae992-c243-4caa-958e-7383f2f1582b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'n_estimators': 150,\n",
              " 'min_samples_split': 50,\n",
              " 'min_samples_leaf': 40,\n",
              " 'max_depth': 30,\n",
              " 'learning_rate': 0.05}"
            ]
          },
          "execution_count": 346,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gbc_grid.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "NYUZ8Ot5eHe5"
      },
      "outputs": [],
      "source": [
        "gbc_optimal_model = gbc_grid.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "OQohji0ceHe6"
      },
      "outputs": [],
      "source": [
        "#class prediction of y on train and test\n",
        "y_pred_gbc_grid=gbc_optimal_model.predict(X_test)\n",
        "y_train_pred_gbc_grid=gbc_optimal_model.predict(X_train)\n",
        "\n",
        "# Get the probabilities on train and test\n",
        "y_pred_prob_gbc_grid = gbc_optimal_model.predict_proba(X_train)[:,1]\n",
        "y_train_pred_prob_gbc_grid = gbc_optimal_model.predict_proba(X_test)[:,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWzKxUCJeHe6",
        "outputId": "aeccc37a-521d-49f7-a98b-8c94988487da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The accuracy on train data is  0.989\n",
            "The accuracy on test data is  0.869\n",
            "The precision on test data is  0.833\n",
            "The recall on test data is  0.898\n",
            "The f1 on test data is  0.864\n",
            "The auc on test data is  0.871\n"
          ]
        }
      ],
      "source": [
        "#getting all scores for Gradient Boosting after CV and Hyperparameter Tunning\n",
        "train_accuracy_gbc_grid = round(accuracy_score(y_train_pred_gbc_grid,y_train), 3)\n",
        "accuracy_gbc_grid = round(accuracy_score(y_pred_gbc_grid,y_test), 3)\n",
        "precision_score_gbc_grid = round(precision_score(y_pred_gbc_grid,y_test), 3)\n",
        "recall_score_gbc_grid = round(recall_score(y_pred_gbc_grid,y_test), 3)\n",
        "f1_score_gbc_grid = round(f1_score(y_pred_gbc_grid,y_test), 3)\n",
        "auc_gbc_grid = round(roc_auc_score(y_pred_gbc_grid,y_test), 3)\n",
        "\n",
        "print(\"The accuracy on train data is \", train_accuracy_gbc_grid)\n",
        "print(\"The accuracy on test data is \", accuracy_gbc_grid)\n",
        "print(\"The precision on test data is \", precision_score_gbc_grid)\n",
        "print(\"The recall on test data is \", recall_score_gbc_grid)\n",
        "print(\"The f1 on test data is \", f1_score_gbc_grid)\n",
        "print(\"The auc on test data is \", auc_gbc_grid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "pjI7KDr-eHe7"
      },
      "outputs": [],
      "source": [
        "# Get the confusion matrices for train and test\n",
        "train_cm_gbc_grid = confusion_matrix(y_train,y_train_pred_gbc_grid)\n",
        "test_cm_gbc_grid = confusion_matrix(y_test,y_pred_gbc_grid )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOUbawG_6Kzs",
        "outputId": "ec466d03-f468-4064-89f7-ca620d539979"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[18595,    96],\n",
              "       [  327, 18364]])"
            ]
          },
          "execution_count": 351,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_cm_gbc_grid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkdjMqri6KxT",
        "outputId": "f2e9d309-2852-4ad5-84c1-27a232584709"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[4231,  442],\n",
              "       [ 779, 3894]])"
            ]
          },
          "execution_count": 352,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_cm_gbc_grid"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhvEJF0frRc1"
      },
      "source": [
        "## **XG Boosting**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "gB3Bm6eE6UfG"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3tRn39OpvrgZ"
      },
      "outputs": [],
      "source": [
        "# Hyperparameter Grid\n",
        "param_dict = {'learning_rate': [0.15, 0.1, 0.05],\n",
        "              'n_estimators' : [200, 250],\n",
        "              'max_depth' : [15,20,25],\n",
        "              'min_child_weight' : [1,3],\n",
        "              'gamma': [0.3, 0.2, 0.1],\n",
        "              'min_samples_leaf' : [40, 50]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ioVWpsUvrge",
        "outputId": "861aa5a2-273f-4a78-bce5-fbb6e245279b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=3, estimator=XGBClassifier(), n_iter=5, n_jobs=-1,\n",
              "                   param_distributions={'gamma': [0.3, 0.2, 0.1],\n",
              "                                        'learning_rate': [0.15, 0.1, 0.05],\n",
              "                                        'max_depth': [15, 20, 25],\n",
              "                                        'min_child_weight': [1, 3],\n",
              "                                        'min_samples_leaf': [40, 50],\n",
              "                                        'n_estimators': [200, 250]},\n",
              "                   scoring='roc_auc', verbose=2)"
            ]
          },
          "execution_count": 355,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create an instance of the RandomForestClassifier\n",
        "xgb = XGBClassifier()\n",
        "\n",
        "# Grid search\n",
        "xgb_grid = RandomizedSearchCV(estimator=xgb,\n",
        "                       param_distributions = param_dict,\n",
        "                       n_jobs=-1, n_iter=5, cv = 3,\n",
        "                       verbose=2, scoring='roc_auc')\n",
        "# fitting model\n",
        "xgb_grid.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPUZED9mvrgg",
        "outputId": "c77f71f8-853e-4322-8f3f-e01689299849"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "XGBClassifier(gamma=0.3, max_depth=15, min_samples_leaf=40, n_estimators=200)"
            ]
          },
          "execution_count": 356,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "xgb_grid.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tXJ9Kiovrgh",
        "outputId": "337eea21-6441-4fab-8c72-673689fd20df"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'n_estimators': 200,\n",
              " 'min_samples_leaf': 40,\n",
              " 'min_child_weight': 1,\n",
              " 'max_depth': 15,\n",
              " 'learning_rate': 0.1,\n",
              " 'gamma': 0.3}"
            ]
          },
          "execution_count": 357,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "xgb_grid.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "tyRAYsFcvrgh"
      },
      "outputs": [],
      "source": [
        "xgb_optimal_model = xgb_grid.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "dPir_y3Gvrgj"
      },
      "outputs": [],
      "source": [
        "#class prediction of y on train and test\n",
        "y_pred_xgb_grid=xgb_optimal_model.predict(X_test)\n",
        "y_train_pred_xgb_grid=xgb_optimal_model.predict(X_train)\n",
        "\n",
        "# Get the probabilities on train and test\n",
        "y_pred_prob_xgb_grid = xgb_optimal_model.predict_proba(X_train)[:,1]\n",
        "y_train_pred_prob_xgb_grid = xgb_optimal_model.predict_proba(X_test)[:,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fZ6TWT6vrgk",
        "outputId": "a4292cf4-9458-4875-b169-9caa2ef96cdc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The accuracy on train data is  0.998\n",
            "The accuracy on test data is  0.87\n",
            "The precision on test data is  0.832\n",
            "The recall on test data is  0.9\n",
            "The f1 on test data is  0.865\n",
            "The auc on test data is  0.872\n"
          ]
        }
      ],
      "source": [
        "#getting all scores for XG Boosting after CV and Hyperparameter Tunning\n",
        "train_accuracy_xgb_grid = round(accuracy_score(y_train_pred_xgb_grid,y_train), 3)\n",
        "accuracy_xgb_grid = round(accuracy_score(y_pred_xgb_grid,y_test), 3)\n",
        "precision_score_xgb_grid = round(precision_score(y_pred_xgb_grid,y_test), 3)\n",
        "recall_score_xgb_grid = round(recall_score(y_pred_xgb_grid,y_test), 3)\n",
        "f1_score_xgb_grid = round(f1_score(y_pred_xgb_grid,y_test), 3)\n",
        "auc_xgb_grid = round(roc_auc_score(y_pred_xgb_grid,y_test), 3)\n",
        "\n",
        "print(\"The accuracy on train data is \", train_accuracy_xgb_grid)\n",
        "print(\"The accuracy on test data is \", accuracy_xgb_grid)\n",
        "print(\"The precision on test data is \", precision_score_xgb_grid)\n",
        "print(\"The recall on test data is \", recall_score_xgb_grid)\n",
        "print(\"The f1 on test data is \", f1_score_xgb_grid)\n",
        "print(\"The auc on test data is \", auc_xgb_grid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "VFgOyD-jvrgl"
      },
      "outputs": [],
      "source": [
        "# Get the confusion matrices for train and test\n",
        "train_cm_xgb_grid = confusion_matrix(y_train,y_train_pred_xgb_grid)\n",
        "test_cm_xgb_grid = confusion_matrix(y_test,y_pred_xgb_grid )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ou4AtBbb5bi"
      },
      "source": [
        "# **Final Model Comparision**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "BrVe-hXPcHzw"
      },
      "outputs": [],
      "source": [
        "grid_classifiers = ['Optimal Logistic Regression', 'Optimal Decision Tree', 'Optimal Random Forest', 'Optimal SVM', 'Optimal Gradient Boosting', 'Optimal XG Boosting']\n",
        "grid_train_accuracy = [train_accuracy_logi_grid, train_accuracy_dtc_grid, train_accuracy_rfc_grid, train_accuracy_svm_grid, train_accuracy_gbc_grid, train_accuracy_xgb_grid]\n",
        "grid_test_accuracy = [accuracy_logi_grid, accuracy_dtc_grid, accuracy_rfc_grid, accuracy_svm_grid, accuracy_gbc_grid, accuracy_xgb_grid]\n",
        "grid_precision_score = [precision_score_logi_grid, precision_score_dtc_grid, precision_score_rfc_grid, precision_score_svm_grid, precision_score_gbc_grid, precision_score_xgb_grid]\n",
        "grid_recall_score = [recall_score_logi_grid, recall_score_dtc_grid, recall_score_rfc_grid, recall_score_svm_grid, recall_score_gbc_grid, recall_score_xgb_grid]\n",
        "grid_f1_score = [f1_score_logi_grid, f1_score_dtc_grid, f1_score_rfc_grid, f1_score_svm_grid, f1_score_gbc_grid, f1_score_xgb_grid]\n",
        "grid_auc_score = [auc_logi_grid, auc_dtc_grid, auc_rfc_grid, auc_svm_grid, auc_gbc_grid, auc_xgb_grid]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "w5Fzkxdcd0fj"
      },
      "outputs": [],
      "source": [
        "grid_compare_df = pd.DataFrame({'Classifier':grid_classifiers, 'Train Accuracy': grid_train_accuracy, 'Test Accuracy': grid_test_accuracy, 'Precision': grid_precision_score, 'Recall': grid_recall_score, 'F1 Score': grid_f1_score , 'AUC': grid_auc_score})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "QwxMONbgXxEr"
      },
      "outputs": [],
      "source": [
        "all_comparision_df = pd.concat([compare_df, grid_compare_df]).reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "icHcQraXi2Sc"
      },
      "outputs": [],
      "source": [
        "all_comparision_df.drop('index', axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "s97G_a3yjGjn"
      },
      "outputs": [],
      "source": [
        "all_comparision_df.sort_values('AUC', axis=0, ascending=False, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "9UcLWjIHkfvm",
        "outputId": "f484dea9-ea25-4115-9841-3df75049b849"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-7c49d7c6-23b6-490d-890d-b62e136b22f8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Classifier</th>\n",
              "      <th>Train Accuracy</th>\n",
              "      <th>Test Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "      <th>AUC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Optimal XG Boosting</td>\n",
              "      <td>0.998</td>\n",
              "      <td>0.870</td>\n",
              "      <td>0.832</td>\n",
              "      <td>0.900</td>\n",
              "      <td>0.865</td>\n",
              "      <td>0.872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>0.999</td>\n",
              "      <td>0.869</td>\n",
              "      <td>0.833</td>\n",
              "      <td>0.897</td>\n",
              "      <td>0.864</td>\n",
              "      <td>0.871</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Optimal Gradient Boosting</td>\n",
              "      <td>0.989</td>\n",
              "      <td>0.869</td>\n",
              "      <td>0.833</td>\n",
              "      <td>0.898</td>\n",
              "      <td>0.864</td>\n",
              "      <td>0.871</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>XG Boosting</td>\n",
              "      <td>0.846</td>\n",
              "      <td>0.848</td>\n",
              "      <td>0.807</td>\n",
              "      <td>0.879</td>\n",
              "      <td>0.842</td>\n",
              "      <td>0.851</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>SVM</td>\n",
              "      <td>0.847</td>\n",
              "      <td>0.841</td>\n",
              "      <td>0.767</td>\n",
              "      <td>0.900</td>\n",
              "      <td>0.828</td>\n",
              "      <td>0.849</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Optimal SVM</td>\n",
              "      <td>0.847</td>\n",
              "      <td>0.841</td>\n",
              "      <td>0.767</td>\n",
              "      <td>0.900</td>\n",
              "      <td>0.828</td>\n",
              "      <td>0.849</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Gradient Boosting</td>\n",
              "      <td>0.846</td>\n",
              "      <td>0.844</td>\n",
              "      <td>0.806</td>\n",
              "      <td>0.872</td>\n",
              "      <td>0.838</td>\n",
              "      <td>0.846</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Optimal Random Forest</td>\n",
              "      <td>0.844</td>\n",
              "      <td>0.833</td>\n",
              "      <td>0.794</td>\n",
              "      <td>0.861</td>\n",
              "      <td>0.826</td>\n",
              "      <td>0.835</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>0.827</td>\n",
              "      <td>0.832</td>\n",
              "      <td>0.796</td>\n",
              "      <td>0.857</td>\n",
              "      <td>0.825</td>\n",
              "      <td>0.833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Optimal Logistic Regression</td>\n",
              "      <td>0.826</td>\n",
              "      <td>0.831</td>\n",
              "      <td>0.796</td>\n",
              "      <td>0.856</td>\n",
              "      <td>0.825</td>\n",
              "      <td>0.833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Optimal Decision Tree</td>\n",
              "      <td>0.836</td>\n",
              "      <td>0.821</td>\n",
              "      <td>0.771</td>\n",
              "      <td>0.857</td>\n",
              "      <td>0.812</td>\n",
              "      <td>0.825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Decision Tree</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.798</td>\n",
              "      <td>0.821</td>\n",
              "      <td>0.785</td>\n",
              "      <td>0.803</td>\n",
              "      <td>0.799</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7c49d7c6-23b6-490d-890d-b62e136b22f8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7c49d7c6-23b6-490d-890d-b62e136b22f8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7c49d7c6-23b6-490d-890d-b62e136b22f8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                     Classifier  Train Accuracy  Test Accuracy  Precision  \\\n",
              "11          Optimal XG Boosting           0.998          0.870      0.832   \n",
              "2                 Random Forest           0.999          0.869      0.833   \n",
              "10    Optimal Gradient Boosting           0.989          0.869      0.833   \n",
              "5                   XG Boosting           0.846          0.848      0.807   \n",
              "3                           SVM           0.847          0.841      0.767   \n",
              "9                   Optimal SVM           0.847          0.841      0.767   \n",
              "4             Gradient Boosting           0.846          0.844      0.806   \n",
              "8         Optimal Random Forest           0.844          0.833      0.794   \n",
              "0           Logistic Regression           0.827          0.832      0.796   \n",
              "6   Optimal Logistic Regression           0.826          0.831      0.796   \n",
              "7         Optimal Decision Tree           0.836          0.821      0.771   \n",
              "1                 Decision Tree           1.000          0.798      0.821   \n",
              "\n",
              "    Recall  F1 Score    AUC  \n",
              "11   0.900     0.865  0.872  \n",
              "2    0.897     0.864  0.871  \n",
              "10   0.898     0.864  0.871  \n",
              "5    0.879     0.842  0.851  \n",
              "3    0.900     0.828  0.849  \n",
              "9    0.900     0.828  0.849  \n",
              "4    0.872     0.838  0.846  \n",
              "8    0.861     0.826  0.835  \n",
              "0    0.857     0.825  0.833  \n",
              "6    0.856     0.825  0.833  \n",
              "7    0.857     0.812  0.825  \n",
              "1    0.785     0.803  0.799  "
            ]
          },
          "execution_count": 367,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_comparision_df"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}